---
title: "Time to next new nuclear-weapon state"
author: "Spencer Graves"
date: "2019-11-20"
output: bookdown::pdf_book
#output: bookdown::gitbook
bibliography: nuc-references.bib
%\VignetteEngine{knitr::knitr}
%\VignetteIndexEntry{Time to next new nuclear-weapon state}
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Abstract

This article models the time between the "first test" of a nuclear weapon by one nation and the next.  It uses this model to obtain confidence bounds on the number of nuclear-weapon states decades into the future.  A plot of the times between "first tests" of the 9 nuclear powers as of 2019-10-15 suggests a nonhomogeneous [renewal process](https://en.wikipedia.org/wiki/Renewal_theory) that suggests a linear decrease in time in log(Poisson mean) of the number of first tests each year by new nuclear-weapon states).  This can be modeled using [`glm(..., family=poisson)`](https://www.rdocumentation.org/packages/stats/versions/3.6.1/topics/glm).  We fit this model and use it to predict the probabilities of further nuclear proliferation.    
  
# Introduction 

The plot of times between "first tests" by the world's nuclear-weapon states as of 2019-05-14 suggests that the process of nuclear proliferation has slowed over time;  see Figure \@ref(fig:plot). 

```{r, plot, fig.cap = "Time between new nuclear-weapon states"}
library(Ecdat)
data(nuclearWeaponStates)
ymax <- max(
  nuclearWeaponStates$yearsSinceLastFirstTest, 
            na.rm=TRUE)
ylim. <- c(0, ymax)
plot(yearsSinceLastFirstTest~firstTest, 
     nuclearWeaponStates, type='h', 
     xlab='', ylab='', las=1, 
     ylim=ylim., bty='n')
#title(
#  'Figure 1. Time between\nnew nuclear nations')
xlab. <- paste(c(
  'Note: The US is not on this plot,',
  'because it had no predecessors.'), 
               collapse='\n')
mtext(xlab., 1, 3)
mtext('years from the\nprevious "first test"',
      2, 2)
with(nuclearWeaponStates, 
  text(firstTest, yearsSinceLastFirstTest,
       ctry, xpd=TRUE))
```

However, it stretches credibility to suggest that nuclear proliferation has stopped.  There were only 5 nuclear-weapon states when the [Treaty on the Non-Proliferation of Nuclear Weapons (NPT, Non-proliferation treaty)](https://en.wikipedia.org/wiki/Treaty_on_the_Non-Proliferation_of_Nuclear_Weapons) entered into force in 1970.  When US President [George W. Bush](https://en.wikipedia.org/wiki/George_W._Bush) decried an ["Axis of evil"](https://en.wikipedia.org/wiki/Axis_of_evil) in his State of the Union message, 29 January 2002, there were 8.  As this is written 2019-10-15, there are 9.  @Toon:2007 noted that in 2003 another 32 had sufficient fissile material to make nuclear weapons if they wished.  

Moreover, those 32 do NOT include either Turkey nor Saudi Arabia.  On September 4, 2019, Turkish President Erdogan said it was unacceptable for nuclear-armed states to forbid Turkey from acquiring its own nuclear weapons.^[@Toksabay:2019; @OConnor:2019] 

In 2006 *Forbes* reported that Saudi Arabia has "a secret underground city and dozens of underground silos for" Pakistani nuclear weapons and missiles.^[@Forbes:SaudiNuc;  see also @Wikip:SaudiNuc.] In 2018 the *Middle East Monitor* reported that "Israel 'is selling nuclear information' to Saudi Arabia".^[@MEM:SaudiNuc;  see also @Wikip:SaudiNuc.]  This is particularly disturbing, because of the substantial evidence that Saudi Arabia may have been and may still be the primary recruiter and funder of Islamic terrorism.^[@Benjamin:2016; see also @Wikiv:WinTerror]  

This analysis suggests that the number of nuclear-weapon states will likely continue to grow until either (i) a nuclear war destroys the ability of anyone to make more nuclear weapons, or (ii) the fundamental structure of international relations changes to the point that any nation that perceives an external threat can confidently rely on international law for protection, without a military that might threaten other countries.

This vignette first reviews the data and history on this issue including brief discussions of what might have motivated different nations to pursue nuclear weapons.  We then consider modeling these data as a series of annual Poisson observations of the number of states conducting a first test of a nuclear weapon each year (1 in each of 8 years since 1945; 0 in the others).  

The simplest such model that considers the possible inhomogeniety visible in Figure \@ref(fig:plot) is [Poisson regression](https://en.wikipedia.org/wiki/Poisson_regression) assuming that log(Poisson mean) is linear in the time since the first test of nuclear weapon by the US in 1945.  We estimate this using [`glm(..., family=poisson)`](https://www.rdocumentation.org/packages/stats/versions/3.6.1/topics/glm).  This model is plausible to the extent that this trend might represent a growing international awareness of the threat represented by nuclear weapons including a hypothesized increasing reluctance of existing nuclear-weapon stated to share their technology. The current process of ratifying the [Treaty on the Prohibition of Nuclear Weapons](https://en.wikipedia.org/wiki/Treaty_on_the_Prohibition_of_Nuclear_Weapons) supports the hypothesis of such a trend, while the lack of universal support for it clearly indicates that nuclear proliferation is still likely to continue.  We use this model to extend the 74 years of history of nuclear proliferation available as this is being written in 2019 into predicting another 74 years into the future. First, however, we review some of the history that may have motivated existing nuclear-weapon states to develop this techology.  

# What motivated the existing nuclear-weapon states to develop this capability?

@Ellsberg:2017 noted that every US president since [Truman (president: 1945-1953)](https://pl.wikipedia.org/wiki/Harry_Truman) considered the use of nuclear weapons.  [With the possible exception of Ford, all threatened to use them, sometimes publicly, sometimes in secret.](https://en.wikipedia.org/wiki/Daniel_Ellsberg#The_Doomsday_Machine)  Countries threatened include the Soviet Union (now Russia), the People's Republic of China, Iraq, Iran, Libya, India, and North Korea.  

One might therefore understand the motivation of North Korea to accelerate their nuclear program in the early 2000s after hearing themselves along with Iran and Iraq described as the ["Axis of evil"](https://en.wikipedia.org/wiki/Axis_of_evil) by US President [George W. Bush](https://en.wikipedia.org/wiki/George_W._Bush) and after then seeing Iran repeatedly threatened and Iraq invaded with [estimated deaths ranging from over 100,000 to over a million](https://en.wikipedia.org/wiki/Iraq_War) out of a population in 2016 of roughly 37 million.  Indeed, any reasonable person might understand the eagerness of North Korean leaders for something that could protect them from similar threats.  

Similar logic might explain why Soviet leaders might have felt a need to defend themselves from nuclear coercion after [having been invaded by the US and over a dozen other countries trying to put the Tsar back in power after World War I](https://en.wikipedia.org/wiki/Allied_intervention_in_the_Russian_Civil_War).  The United Kingdom and France likely felt nuclear threats from the Soviet Union.  China faced nuclear threats from the US regarding Korea and the Taiwan Strait.  India faced major threats from China, [^India] Pakistan from India,[^Pak] and Israel from its neighbors.[^Israel]

More generally the history of US belicosity includes [invading Canada in 1812](https://www.history.com/news/how-u-s-forces-failed-to-conquer-canada-200-years-ago)^[@Berton:1980] and [numerous other foreign interventions](https://en.wikipedia.org/wiki/Foreign_interventions_by_the_United_States) including invading [Afghanistan in 2001](https://en.wikipedia.org/wiki/War_in_Afghanistan_(2001%E2%80%93present)), and [Iraq in 2003](https://en.wikipedia.org/wiki/Iraq_conflict_(2003%E2%80%93present)), plus continued threats against Iran, North Korea, and now Venezuela.  This history might help people understand how leaders in many countries may be concerned about their own security if they fail to do what the US demands of them.  The [extra-judicial execution of Osama bin Laden and four others in his household by SEAL Team 6](https://en.wikipedia.org/wiki/Death_of_Osama_bin_Laden) on 2011-05-02 has reportedly increased the risks that a Pakistani nuclear weapon might be stolen by Islamic terrorists intent on retaliating against the US for its interventions in Pakistan and neighboring countries.^[@Cohen:2009;  see also @Borger:2010] 

<center>
***The September 11th attacks***

***might have been a mushroom cloud.***  
</center>
<cr>

In this context, declassified US government documents establish that in the 1980s, when the US was clandestinely supporting the Contra war against Nicaragua in violation of US law, it was also [secretly helping the Pakistani nuclear program in violation of US law.  This was done to secure Pakistani cooperation with US support for anti-Soviet resistance in Afghanistan](https://www.wilsoncenter.org/publication/new-documents-spotlight-reagan-era-tensions-over-pakistani-nuclear-program).^[@Burr:2012, @Burr:2013] 

Without this, "the nuclear weapons programmes of Iran, Libya and North Korea - which British and American intelligence now acknowledge were all secretly enabled by Pakistan - would never have got off the ground," according to [Robert Gallucci](https://en.wikipedia.org/wiki/Robert_Gallucci), special adviser on WMDs to President Clinton.^[The quote is from @Levy:2007.   That article claims he was a special adviser on WDMs to both Clinton and G. W. Bush.  However, the Wikipedia article and @Gallucci:2001 both indicate he left government service in January 2001;  G. W. Bush took office 2001-01-20.]  

Similar comments have been made by [Richard Barlow](https://en.wikipedia.org/wiki/Richard_Barlow_(Intelligence_analyst)#cite_note-wp-1), a CIA analyst who reported these questionable activities to a committee of the US House.^[@Levy:2007. Barlow was reportedly severely punished for honestly answering questions in a classified briefing to an oversight committee of the US House.  Barlow described US assistance to Pakistan's nuclear weapons program in exchange for Pakistan's help in supplying rebels in Afghanistan fighting Soviet occupation.  This was during the [Iran-Contra affair](https://en.wikipedia.org/wiki/Iran%E2%80%93Contra_affair), which exposed actions of officials of the Reagan administration to pursue foreign policy objectives in Central America in blatant violation of law passed by Congress and signed by the President.]

And now the US is helping Saudi Arabia obtain nuclear power, in spite of (a) the evidence that [the Saudi government including members of the Saudi royal family were  involved in preparations for the suicide mass murders of September 11, 2001, at least as early as 1999](https://en.wikipedia.org/wiki/The_28_pages) and (b) their [on-going support for Al Qaeda in Yemen, reported as recently as 2019](https://en.wikipedia.org/wiki/Saudi_Arabian-led_intervention_in_Yemen). 

**Conclusions**:  
 
  1. There seems to be no shortage of motivations for other countries to acquire nuclear weapons.  
  
  2. The knowledge and materials required to make such weapons in a relatively short order are also fairly widely available, even without the documented willingness of current nuclear powers to secretly help other countries acquire such weapons.[^quickNukes]  
  
  3. Unless there is some fundamental change in the structure of international relations, it seems unwise to assume that there will not be more nuclear nations in the future, with the time to the next "first test" of a nuclear weapon following a probability distribution consistent with the previous times between "first tests" of nuclear weapons by new nuclear-weapon states.  

# Exponential time between Poisson 'first tests' 

Possibly the simplest model for something like the time between 'first tests' in a situation like this is to assume they come from one [exponential distribution](https://en.wikipedia.org/wiki/Exponential_distribution) with 8 observed times between the 9 current nuclear-weapon states plus one [censored observation](https://en.wikipedia.org/wiki/Censoring_(statistics)) of the time between the most recent one and a presumed next one.[^WikivTime]  

However, Figure \@ref(fig:plot) suggests that the time between 
'first tests' of succeeding nuclear-weapon states is increasing.  This makes it difficult to use censored data estimation as just described.  

To understand the current data better, we redo Figure \@ref(fig:plot) with a log scale on the y axis in Figure  \@ref(fig:ploty).   

```{r ploty, fig.cap = "Time between new nuclear-weapon states"}
library(Ecdat)
plot(yearsSinceLastFirstTest~firstTest, 
     nuclearWeaponStates, type='n', 
     xlab='', ylab='', las=1, log='y',
     bty='n')
#title(
#'Figure 2. Time between\nnew nuclear-weapon states')
mtext('Note: The US is not on this plot,\nbecause it had no predecessors.', 1, 3)
mtext('years from the\nprevious "first test"', 2, 2)

with(nuclearWeaponStates, 
  text(firstTest, yearsSinceLastFirstTest,
       ctry, xpd=TRUE))
```

Figures \@ref(fig:plot) and \@ref(fig:ploty) seem consistent with the following:

- Time between events might be exponentially distributed but with a hazard rate that varies over time.  [Recall that the [hazard rate](https://en.wikipedia.org/wiki/Survival_analysis#Hazard_function_and_cumulative_hazard_function) for the exponential distribution is constant: $h(t) = (-d/dt \log S(t)) = \lambda$, writing the exponential survival function as $S(t) = \exp(-\lambda t)$.]  This is consistent with the apparent increase in the time to the next "first test" by a new nuclear-weapon state.  However, the time between such "first tests" might decrease in the future if more states began to perceive greater threats from other nations.  
- Log hazard that is either linear in the time since the first test of a nuclear weapon, code-named ["Trinity"](https://en.wikipedia.org/wiki/Trinity_(nuclear_test)), or behaves like a ["Wiener process" (also called a "Brownian motion")](https://en.wikipedia.org/wiki/Wiener_process), which means that the variance of the increments in log(hazard) between "first tests" is proportional to the elapsed time.  In this article, we model the trend as linear and leave consideration of a [Gaussian random walk](https://en.wikipedia.org/wiki/Random_walk) and similar stochastic formulations for future work.[^ranWalk]

Because of the well-known duality between the [exponential distribution](https://en.wikipedia.org/wiki/Exponential_distribution) and the [Poisson distribution](https://en.wikipedia.org/wiki/Poisson_distribution), we can also model this as a series of the number of events each year, month, week, or day.  For present purposes, we will use a series of annual observation.  Changing to monthly, weekly or daily observations might give us slightly better answers while possibly increasing the compute time more than it's worth.  

# Parameter estimation 

For modeling and parameter estimation, we use [`glm(firstTests ~ timeSinceTrinity, poisson)`](https://www.rdocumentation.org/packages/stats/versions/3.6.1/topics/glm) with:   

- `firstTests` = the number of first tests of a nuclear-weapon by a new nuclear-weapon state each year, and   
- `timeSinceTrinity` = number of years since 1945-07-16, when the first nuclear weapon was tested, code-named ["Trinity"](https://en.wikipedia.org/wiki/Trinity_(nuclear_test)).  

We use the [`lubridate` package](https://lubridate.tidyverse.org/) for dates.  The first thing we want is the current year.  We get that starting with [`today`](https://www.rdocumentation.org/packages/lubridate/versions/1.7.4/topics/today):  

```{r today}
library(lubridate)
(Today <- today())
```

From this we get the year:  

```{r year}
(currentYear <- year(Today))
```

Let's include an observation for the current year only if it's more than 6 months since January 1 and since the last "first test":  

```{r currentYear}
if((month(Today)<7) || 
   (difftime(Today, 
          tail(nuclearWeaponStates$firstTest, 1), 
          units = 'days')<(366/2)))
      currentYear <- (year(Today)-1)
```

Start after the year of the first test of a nuclear weapon:  

```{r firstYear}
firstTstYr <- year(nuclearWeaponStates$firstTest)
(firstYear <- firstTstYr[1])
```

Now let's create a vector of the number of "firstTests" by year:  

```{r firstTests}
(nYrs <- currentYear - firstYear)
firstTests <- ts(rep(0, nYrs), firstYear+1)
firstTstYrSinceFirst <- firstTstYr - firstYear
firstTests[firstTstYrSinceFirst] <- 1

library(tibble)
#(FirstTsts <- tibble(Year=time(firstTests), 
#      nFirstTests=as.numeric(firstTests)))
(FirstTsts <- tibble(Year=time(firstTests), 
      nFirstTests=firstTests))
```

Add `ctry` to this tibble:  

```{r firstCtry}
Ctry <- rep('', nYrs)
Ctry[firstTstYrSinceFirst] <- 
        nuclearWeaponStates$ctry[-1]
FirstTests <- cbind(FirstTsts, ctry=Ctry)
```

And add `timeSinceTrinity`:  

```{r timeSince}
FirstTests$timeSinceTrinity <- 1:nYrs
```

Now fit this model:  

```{r fit1}
summary(PoissonFit <- glm(
  firstTests ~ timeSinceTrinity, 
  poisson, FirstTests))
```

This says that the time trend visible in Figures \@ref(fig:plot) and \@ref(fig:ploty) is not statistically significant.  

[George Box](https://en.wikipedia.org/wiki/George_E._P._Box) famously said that, ["All models are wrong, but some are useful."](https://en.wikipedia.org/wiki/All_models_are_wrong#Historical_antecedents) 

@Burnham:1998 and others claim that better predictions can generally be obtained using Bayesian Model Averaging.^[See also @Burnham:2002 and Claeskens:2008.] In this case, we have two models:  `log(Poisson mean)` being constant or linear in `timeSinceTrinity`.  The [`bic.glm`](http://finzi.psych.upenn.edu/R/library/BMA/html/bic.glm.html) in the [`BMA`](http://finzi.psych.upenn.edu/R/library/BMA/html/bic.glm.html) package can estimate these two models for us and compute the posterior probabilities as follows:  

```{r BMA}
library(BMA)
(fitProlif <- bic.glm(
  FirstTests['timeSinceTrinity'], 
  FirstTests$nFirstTests, 
  "poisson"))
```

It is standard in the BMA literature to assume an approximate uniform distribution over all models considered with a penalty for estimating each additional parameter to correct for the tendancy of the models to overfit the data.  With these standard assumptions, this comparison of these two models estimates a 21.4 percent posterior probability for model including `timeSinceTrinity`, leaving 78.6 percent probability for the model with constant Poisson mean.  

There are three types of intervals we will use with predicting future nuclear proliferation based on the fitted BMA model:  

  - [Central 80 ppercent confidence intervals](https://en.wikipedia.org/wiki/Confidence_interval) for the predicted mean number of nuclear-weapon states for each future year considered.  
  
  - [Central 80 percent prediction intervals](https://en.wikipedia.org/wiki/Prediction_interval) for the actual number of nuclear-weapon states, combining the uncertainty in the Poisson process modeled with the uncertainty of estimating its mean for each future year considered.  
  
  - [Central (80, 80) percent tolerance intervals](https://en.wikipedia.org/wiki/Tolerance_interval#Relation_to_other_intervals) showing the uncertainty in the associated Poisson process separate from the model estimation uncertainty for each future year considered.  
  
# Tolerance intervals    
  
We will start by computing `nSims` simulated Poisson mean numbers of "first tests" by new nuclear-weapon states for of the `nYrs` future years for which predictions are desired.  These simulations will later be used to compute prediction intervals.  
  
First, however, we  [`cumsum`](https://www.rdocumentation.org/packages/base/versions/3.6.1/topics/cumsum) the predicted Poisson means then add the current number of nuclear-weapon states (9 as this is written on 2019-12-01) and compute the mean and (0.1, 0.5, 0.9) proportion quantiles to obtain the desired confidence intervals on the predicted 
for each future year of interest.  

% ```{r meanSims}
set.seed(1)

simulate.


```

# Prediction intervals

The simplest bounds on the future are [prediction intervals](https://en.wikipedia.org/wiki/Prediction_interval), which combine the statistical uncertainty in the models with the random variability in the outcomes.  For this, we proceed as follows:  

  1.  Select either the constant or the linear model with the estimated posterior probabilities.
  
  2.  For the selected model, compute at random one set of estimated parameter(s) using the approximating normal posterior.  
  
  3.  Convert the estimated parameters into an estimate of the Poisson mean for each year for which a prediction is desired.  
  
  4.  Simulate Poisson draws for each desired simulated year.  
  
  5.  Compute the [`cumsum`](https://www.rdocumentation.org/packages/base/versions/3.6.1/topics/cumsum) of the simulated Poisson draws and add the current number of nuclear-weapon states (9 as this is written 2019-12-01).    
  
  6.  Compute the mean as well as the (0.1, 0.5, 0.9) proportion quantiles of the cumsum.  
  
  7.  Plot the results.  







$$
\mathsf{AIC}_\mathsf{c} = 2 k \left(\frac{n}{n-k-1}\right) - 2 \log(\mathsf{likelihood}). 
$$

With this, the posterior probability for model $M_i$ is given by the following: 

$$
\mathsf{Pr}(M_i|\mathsf{data}) \propto \exp(-\mathsf{AIC}_\mathsf{c} / 2).  
$$




Let's look at the log(Poisson mean) itself, alpha, for the last 6 years.  Note that `dim(firstTstsSim$states$Mean)` is 75 x 1, being one more year than the number of observations by the number of states.  There are 74 years between 1945 and 2019, and this model has a one-dimensional state, being the level.  

 {r alph}
level <- expand_sample(firstTstsSim, "alpha", 
            times=c(1:3, 10, 25, 50, 65, 73:75))
str(level)
```

This is a list of length 1, because this model has a unidimensional state vector.  `level$level` gives 10 sample times from each of 2500 trajectories of length 75, one more than the length of the time series used to fit `firstTstsMdl`.

 {r alphDist, fig.cap='Posterior distributions of the drift in log(Poisson mean); bw=0.005'}
mcmc_areas(level, bw=0.005)
```

The bw (bandwidth) = 0.005 was copied from an example in the [`bssm` vignette](https://www.rdocumentation.org/packages/bssm/versions/0.1.8/vignettes/bssm.Rmd).  The image in Figure \@ref(fig:aplhDist) suggests that 0.005 is too small.  In experimenting with this parameter, it seemed that bw = 0.1 still showed artifacts that were not replicated between different time periods, while bw = 0.3 did not show some features that were replicated between 70, 71, ..., 75 with bw = 0.2.  Therefore, I decided to use the latter in Figure \@ref(fig:alphDist2).  

 {r alphDist2, fig.cap='Posterior distributions of the drift in log(Poisson mean); bw=0.2'}
mcmc_areas(level, bw=0.2)
```

These distributions display the decline we expected in the median over time with greater uncertainty at the beginning and the end, again as we expected.  The last few distributions show a negative skew.  Might that suggest that in this case, the absence of evidence (i.e., that there have been no "first tests" since 2006) may be some evidence of absence?  

Let's look at the trend over the entire period.  The [`bssm` vignette](https://www.rdocumentation.org/packages/bssm/versions/0.1.8/vignettes/bssm.Rmd) uses the [`summary.mcmc_output` function](https://www.rdocumentation.org/packages/bssm/versions/0.1.8/topics/summary.mcmc_output) for this.  That computes means and standard deviations for parameters estimated and the trajectories of the state vector.  However, we will want to compute the [`cumsum`](https://www.rdocumentation.org/packages/base/versions/3.6.1/topics/cumsum) of the Poisson means;  for that we will work directly with `expand_sample(firstTstsSim, "alpha")`.  

First, we plot the normal approximate confidence intervals with those estimated directly from the quantiles of the MCMC simulations in Figure \@ref(fig:sumTrend). 

  {r sumTrend, fig.cap='Mean number of first tests each year'}
firstTstsSum <- summary(firstTstsSim)
lvl <- firstTstsSum$states$Mean[, 1]
lwr <- lvl - 1.96*firstTstsSum$states$SD[, 1]
upr <- lvl + 1.96*firstTstsSum$states$SD[, 1]
vlu <- cbind(lvl, lwr, upr)
VLU <- exp(vlu)

firstTstsSims <- expand_sample(firstTstsSim,
                               'alpha')
firstTstsQ <- apply(firstTstsSims$level, 2, 
        quantile, probs=c(.025, .5, .975))
firstTstsQlog <- ts(t(firstTstsQ), 
                    firstYear+1)
firstTstsQuant <- exp(firstTstsQlog)

op <- par(mar=c(5,4,4,4))
ts.plot(VLU, firstTstsQuant, 
    col=c(2, 5, 5, 3, 4, 3), 
    lty=c(1, 3, 3, 2, 2, 2), log='y', 
    gpars=list(las=1), xlab='', 
    ylab='Poisson mean')
#,main=paste('Mean number of first tests', 
#               'each year') )

# add a scale for log(Poisson mean)
lvlLims <- range(lwr, upr, firstTstsQ)
lvlLogTicks <- pretty(lvlLims)
axis(4, exp(lvlLogTicks), lvlLogTicks, 
     las=1)
mtext('log(Poisson mean)', 4, 2)
legend('bottomleft', 
  legend=c('mean', 
    '95% CI (normal approx)', 
    'median', 
    '95% CI (MCMC)'), 
  col=c(2, 5, 4, 3), 
  lty=c(1, 3, 2, 2), bty='n')
par(op)
```

Note that 'alpha' here is the log(Poisson mean) of the expected number of first tests each year by a new nuclear-weapon state.  That's labeled in the scale on the left of this plot.  The raw numbers were exponentiated to get the Poisson mean, then plotted on a log scale, which is the standard scale for modeling Poisson rates like this. 

The reciprocal of the Poisson mean in a context like this is the mean time (number of years) to the next event, being the expected number of years to the next "first test" by a new nuclear-weapon state.  (If the Poisson mean were constant, [the probability distribution of the time to the next event would be exponential](https://en.wikipedia.org/wiki/Exponential_distribution).)

I'd like to superimpose the actual data from `nuclearWeaponStates` as plotted above on a log scale. However, the dates above are of class `Date`, which are numbers of days since 1970-01-01.  However, for this plot the horizontal axis is in numbers of years.  For this, we use column `firstTestYr` rather than `firstTest`.  The numbers are essentially the same, except that `firstTest` is of class "Date", being numbers of days since 1970-01-01, while `firstTestYr` gives essentially the same number in years and fractions in the [Common Era (CE)](https://en.wikipedia.org/wiki/Common_Era#History_of_the_use_of_the_CE/BCE_abbreviation).  

 {r numericYears, fig.cap="Time to next 'first test' by a new nuclear-weapon state"}
mainExp <- paste("Time to next", 
    "'first test'\nby a new", 
    "nuclear-weapon state")

ts.plot(1/VLU, 1/firstTstsQuant, 
    col=c(2, 5, 5, 3, 4, 3), 
    lty=c(1, 3, 3, 2, 2, 2), log='y', 
    gpars=list(las=1), xlab='', 
    ylab="years to next 'first test'")
#,main=mainExp)

legend('topleft', 
  legend=c('mean', 
    '95% CI (normal approx)', 
    'median', 
    '95% CI (MCMC)'), 
  col=c(2, 5, 4, 3), 
  lty=c(1, 3, 2, 2), bty='n')
abline(h=c(5, 10, 20), lty=2)

# plot actual points 

with(nuclearWeaponStates, 
  text(firstTestYr, yearsSinceLastFirstTest, 
       ctry, xpd=TRUE))

1/VLU[1, ]
1/tail(VLU, 1)
apply(1/VLU, 2, quantile, 
      probs=c(0, .025, .5, .975, 1))
```  

The result is available in Figure \@ref(fig:numericYears). 

This seems consistent with the plot of the data above:  There were 8 'first tests' by a new nuclear-weapon state in the 74 years since the first test by the US, which had no predecessor.  If the mean were constant, it would be 74 / 8 = 9.25 years between 'first tests', which seems consistent with the plot.   

This plot displays an estimated mean time to the next 'first test' starting around 7 years and increasing after 1960 to over 13 years, on average. 

It seems somewhat surprising that the line doesn't go between RU and GB and between FR and CN.  However, the arguments that should affect that, `a1`, `P1`, and `sd_level`, were set at levels that would support this. 

Apart from that, these estimates overall seem plausible.  

Let's check one more thing to evaluate our understanding of the MCMC algorithm used:  Is there a relationship between the root mean square of  [`diff`](https://www.rdocumentation.org/packages/base/versions/3.6.1/topics/diff) of each simulated trajectory of log(Poisson mean) and the corresponding element of `theta`?  

```{r rms}



```

# Cumulative number of nuclear-weapon states

What about the cumulative number of nuclear-weapon states?  This should be [`cumsum(exp(alpha))`](https://www.rdocumentation.org/packages/base/versions/3.6.1/topics/cumsum), adding 1 for the US.  

However, we cannot get confidence limits on the `cumsum` by summing the individual confidence limits, for the same reason that the standard deviation of a sum of random variables is generally not the sum of their standard deviations.  We need to compute the mean and quantiles of the  (`n_iter - n_burnin`) simulations retained after burn-in for each simulated year:  

 {r newNucStates}
lvlAll <- expand_sample(firstTstsSim, "alpha")
str(lvlAll)
lvlEnew <- ts(exp(t(lvlAll$level)), firstYear+1)
str(lvlEnew)
plot(lvlEnew[, 1:10])
```

This shows something of how the `bssm` MCMC algorithm works:  A visual inspection of one simulation suggested that the first 10 of the 2500 simulated series include only 4 unique simulations replicated 2, 2, 1, and at least 5 times, which matches `firstTstsSim$counts[1:4]`:

 {r firstTstsCounts}
firstTstsSim$counts[1:5]
```

`str(firstTstsSim)` above showed that "Length of the final jump chain = 648" for one simulation.  

The `cumsum` of each simulation in `lvlEnew` represents the simulated expected number of new nuclear-weapon states since the US became the first in 1945.  Add one to get the expected total number of nuclear-weapon states over time in each of the 2500 simulations:  

 {r nucStts}
str(lvlEnuc2 <- apply(lvlEnew, 2, cumsum))
plot(lvlEnuc2[, 1])
```

Confirmed that this gives us a cumulative sum.  

 {r nucStates}
lvlEnucStates <- ts(1+lvlEnuc2, firstYear+1) 
str(lvlEnucStates)
lvlMean <- ts(apply(lvlEnucStates, 1, mean), 
                    firstYear+1) 
str(lvlMean)
lvlQuant <- ts(t(apply(lvlEnucStates, 1, 
      quantile, probs=c(0.025, .5, .975))),
                    firstYear+1) 
str(lvlQuant)

ts.plot(lvlMean, lvlQuant, 
    col=c(2, 3, 4, 3), 
    lty=c(1, 2, 2, 2), log='y', 
    gpars=list(las=1), xlab='', 
    ylab='Number of nuclear-weapon states', 
    main=paste('Number of nuclear-weapon',
               'states by year') )

legend('bottomright', 
  legend=c('mean', 
    'median', 
    '95% CI (MCMC)'), 
  col=c(2, 4, 3), 
  lty=c(1, 2, 2), bty='n')

fT_date <- c(nuclearWeaponStates$firstTestYr, 
             currentYear+1)
nNucStates <- nrow(nuclearWeaponStates)
lines(fT_date, 
    c(1:nNucStates, nNucStates), type='s')
```

The upper and lower limits display the range of plausibilty for trajectories of the meanes of Poisson processes consistent with the available data:  Lines below the lower limit would not likely have produced as many nuclear-weapon states during this period as we have today.  Lines above the upper limit likely would have produced more than the number that exists today.  

The median goes right through the available data.  The mean looks a little high.  Overall this looks like a great fit, apart from the fact that all the increments decrease log(Poisson mean).  For that we should consider adding a slope term to the model, which we consider next.  

# Growing understanding of the risks 

The model considered so far assumes a Gaussian random walk in one dimension.  

The last plot suggest we consider adding another term, linear in log(time since the very first test of a nuclear weapon by the US).  

Before trying a more sophisticated model, let's plot the estimated trend above by itself to see if that supports adding log(time since the very first test of a nuclear weapon by the US) to the model.  

 {r plotTrend0}
op <- par(mar=c(5,4,4,4))
ts.plot(exp(lvl), gpars=list(las=1),
      xlab='', ylab='Poisson mean', 
      main=paste("mean number of 'first tests'",
          "each year"), log='y')

# add a scale for log(Poisson mean)
lvlLim1 <- range(lvl)
lvlLogTick1 <- pretty(lvlLim1)
axis(4, exp(lvlLogTick1), lvlLogTick1, 
     las=1)
mtext('log(Poisson mean)', 4, 3)
par(op)
```

The plot of log(Poisson rate) vs. time encourages us to consider adding time as a linear term.  A state-space model that is essentially equivalent has a slope term.

The same [`ng_bsm` function](https://www.rdocumentation.org/packages/bssm/versions/0.1.7/topics/ng_bsm) used above includes an `sd_slope` argument, which is "A fixed value or a prior for the standard error of the noise in slope equation."  Let's specify that as a normal with mean 0 and standard deviation being the root mean square increments in the estimate of level in the level-only model above:  

 {r firstTstsPois1}
firstTstsLin <- ng_bsm(FirstTests$nFirstTests, 
    sd_level=halfnormal(sd_lvl, 10*sqrt(P1)), 
    sd_slope=normal(0, 0, sd_lvl), 
    a1=c(a1, -sd_lvl), P1=P1*diag(c(1, 100)), 
    distribution='poisson')
str(firstTstsLin)
```

Let's proceed to estimate parameters as before:  

 {r run_mcmc2}
set.seed(2)
firstTstsSim2 <- run_mcmc(firstTstsLin, 
          nsim_states=2, n_iter = 5000)
firstTstsSim2
```

This says, "Acceptance rate after the burn-in period:  0".  Let's try to tighten the prior:  

 {r firstTstsPois2}
firstTstsLin2 <- ng_bsm(FirstTests$nFirstTests, 
    sd_level=halfnormal(sd_lvl, 0.1*sqrt(P1)), 
    sd_slope=normal(0, 0, 0.1*sd_lvl), 
    a1=c(a1, -sd_lvl), P1=0.01*P1*diag(c(1, 1)), 
    distribution='poisson')
#str(firstTstsLin2)
```

Let's proceed to estimate parameters as before:  

 {r run-mcmc2a}
set.seed(3)
firstTstsSim2a <- run_mcmc(firstTstsLin, 
          nsim_states=2, n_iter = 5000)
firstTstsSim2a
```

The acceptance rate is still 0.  Maybe a model this complicated cannot be estimated with the available data.  

We therefore return to the first model and see what predictions we can get from that.  

# Predict 

Let's use the 74 years of history available in late 2019 to predict another 74 years into the future.  For this, we use [predict.mcmc_output](https://www.rdocumentation.org/packages/bssm/versions/0.1.7/topics/predict.mcmc_output).  We start by producing a `future_model`, as in the example in the help page and the `bssm` vignette:  

 {r futureModel}
firstTstsFutureMdl <- firstTstsMdl
firstTstsFutureMdl$y <- ts(rep(NA, 74), 
                    start=currentYear+1)
```

 {r predict-mcmc}
set.seed(4)
firstTstsPred_r <- try(predict(firstTstsSim,
      firstTstsFutureMdl, 
      return_MCSE = TRUE))
str(firstTstsPred_r)
with(firstTstsPred_r, ts.plot(
  mean, intervals, gpars=list(las=1), 
  main='predict(...type="response")', 
  col=1:4, lty=1:4, lwd=c(1,2,2,2)) )
legend('topleft', 
  legend=c('mean', "95%", "50%", "5%"), 
  col=c(1, 4:2), lty=c(1, 4:2),
  lwd=c(1,2,2,2), bty='n')

firstTstsPred_m <- try(predict(firstTstsSim,
      type='mean', firstTstsFutureMdl, 
      return_MCSE = TRUE))
str(firstTstsPred_m)
with(firstTstsPred_m, ts.plot(
  mean, intervals, gpars=list(las=1), 
  main='predict(...type="mean")', 
  col=1:4, lty=1:4, lwd=c(1, 2,2,2)) )
legend('topleft', 
  legend=c('mean', "95%", "50%", "5%"), 
  col=c(1, 4:2), lty=c(1, 4:2),
  lwd=c(1,2,2,2), bty='n')

firstTstsPred_s <- try(predict(firstTstsSim,
      type='state', firstTstsFutureMdl, 
      return_MCSE = TRUE))
str(firstTstsPred_s)
with(firstTstsPred_s, ts.plot(
  mean, intervals$level, 
  gpars=list(las=1), 
  main='predict(...type="state")', 
  col=1:4, lty=1:4, lwd=c(1,2,2,2)) )
legend('topleft', 
  legend=c('mean', "95%", "50%", "5%"), 
  col=c(1, 4:2), lty=c(1, 4:2),
  lwd=c(1,2,2,2), bty='n')
```

It's not obvious what type = "response" or "mean" are in this context, but type = "state" seems potentially useful.  

However, we really want the cumsum(annual Poisson counts).  To get that, it would be easiest if we had simulated trajectories of log(Poisson means of annual counts).  Then we could compute cumsum(exp(log(Poisson means))) and compute mean and quantiles from those numbers.    

From that, we could estimate the probability of 0, 1, 2, or more currently non-nuclear states (or non-state rebel groups) becoming nuclear as a function of the time into the future. 

We will construct these manually in two different ways:   

* Assuming the annual changes in log(Poisson mean number of new nuclear-weapon states each year) have mean 0 and standard deviation given by the estimate of `theta` in each accepted MCMC simulation. 

* Using the estimated first differences from the level-only model.  






The first gives pessimistic estimates, basically assuming that the trend toward decreasing hazard showing in the plots in the introduction above could be reversed by a new arms race exemplified by the current nuclear expansion programs in India, Pakistan, the US,^[@Shultz:2019; @Helfand:2019] and Russia as well as the declared desire of the President of Turkey for nuclear weapons^[@OConnor:2019] and the increased threat that such weapons could fall into the hands of terrorists who believe that Armageddon may be a good thing, for whom the possession of nuclear weapons is more of a motivator than a deterrent.^[@Bacevich:2008, pp. 178-179; @Cohen:2009;  see also @Borger:2010]

The second essentially assumes a continuation of the trend visible in the plots above showing gradual reductions in the rate of nuclear proliferation.  

We will examine these two alternative simulations in the order stated, recognizing that the reality could be some in between with a nonzero probability of the elimination of the threat through the entering into force of the International Treaty on the Abolition of Nuclear Weapons, followed by the success of other more aggressive efforts to strengthen international law to the point that any nation that invades another can expect massive nonviolent retaliation in trade restrictions and confiscation of foreign held property of people in the nation of the apparent aggressor(s).  

# Predictions assuming the level-only model

Our primary model estimated in `firstTstsSim` assumes that log(Poisson mean) follows a random walk with independent annual increments of mean 0 and standard deviation `theta`.  Our approach here will iterate over all 2500 accepted simulations after burn-in, matching the log(Poisson mean[2020]) from `firstTstsSims$level[i, 75]` with the estimate of the corresponding standard deviation in theta[i, 1]:

 {r manualPred}
manPred <- ts(matrix(NA, 75, 2500), 
    start=currentYear+1)

manPred[1, ] <- (firstTstsSims$level[,
      75] + rnorm(75, 0, theta[, 1]) )

for(iyr in 2:75){
  manPred[iyr, ] <- (manPred[iyr-1, ] + 
        rnorm(2500, 0, theta[, 1]) )
}
```

Next we want to exponentiate these numbers and cumsum each row to get the expected number of new nuclear-weapon states for each simulated future year:  

 {r predCumsum}
str(predEnuc2 <- ts(apply(exp(manPred), 2,
          cumsum), currentYear+1) )
ts.plot(predEnuc2[, 1:10], lty=1:10, col=1:10)
```

Now let's add the current nuber of nuclear weapon states, 9 as this is being written on 2019-11-02, to predict the total number of nuclear-weapon states for the next 74 years:    

 {r predStates}
predEnucStates <- (9+lvlEnuc2) 
predEnucStates <- ts(9+lvlEnuc2,
                  currentYear+1) 
str(predEnucStates)
predMean <- ts(apply(predEnucStates, 
        1, mean), currentYear+1) 
str(predMean)
predQ <- apply(predEnucStates, 1, 
    quantile, probs=c(0.05, .5, .95))
predQuant <- ts(t(predQ),
                currentYear+1) 
str(predQuant)

yLab <- 'number of nuclear-weapon states'
plot(c(firstYear, currentYear+75), 
     c(1, max(predQuant)), type='n', 
     xlab='', ylab=yLab, las=1)
lines(fT_date, 
    c(1:nNucStates, nNucStates), type='s')
lines(predMean, lty=2, col=2)

predYrs <- time(predQuant)
matlines(predYrs, predQuant, lty=2, 
      col=c(3, 4, 3) )
      
legend('topleft', 
  legend=c('mean', 
    'median', 
    '90% CI (MCMC)'), 
  col=c(2, 4, 3), 
  lty=c(1, 2, 2), bty='n')
```

The model assumes that the `log(level[i])`, where `i` = a year after 2020, is based on the following recursion:  

<center>
`log(Poisson mean[i+1]) = log(Poisson[i]) + (independent random increment)`.
</center>
<cr>

The mean of the independent increments is 0 with a standrd deviation given by the posterior distribution of the variable `theta` described above. 

Let's start by selecting nYrs from the available MCMC simulations after burn-in:

 {r sample}
firstTstsFutureMdl$smpl <- sample(
  with(firstTstsSim, n_iter - n_burnin),
  nYrs)
plot(firstTstsFutureMdl$smpl)
```

We select MCMC samples this way, in case there's a relationship between the MCMC simulations in `theta` and `alpha` stored in `firstTstsSim`, above.  

Now let's select the log(Poisson mean) for each predicted year from the distribution for `(currentYear+1)`:  

 {r simLevel}
firstTstsFutureMdl$simLevel <- ts(
  lvlAll$level[firstTstsFutureMdl$smpl, 
        nYrs+1], currentYear+1)
```

Let's similary select the standard deviation of these estimated levels from `theta`: 

 {r simSD}
firstTstsFutureMdl$simSD <- ts(
  theta[firstTstsFutureMdl$smpl, 1], 
  currentYear+1)
```

Now let's predict the future mean number of nuclear-weapon states by adding `cumsum(exp(firstTstsFutureMdl$simLevel))` to the current number of nuclear-weapon states:  

 {r predNucStates}
firstTstsFutureMdl$predNucStates <- 
  nrow(nuclearWeaponStates) + cumsum(exp(
    firstTstsFutureMdl$simLevel))
plot(firstTstsFutureMdl$predNucStates)
```


)


Similarly, the variance of the prediction e


at time $t$, where $t$ > 
independent normal increments to 





# Conclusions 

This article has modeled the production of nuclear-weapon states as a renewal process with non-identially distributed times between events.  People like [Robert McNamara](https://en.wikipedia.org/wiki/Robert_McNamara), [Daniel Ellsberg](https://en.wikipedia.org/wiki/Daniel_Ellsberg), [Henry Kissinger](https://en.wikipedia.org/wiki/Henry_Kissinger), [William Perry](https://en.wikipedia.org/wiki/William_Perry), [Sam Nunn](https://en.wikipedia.org/wiki/Sam_Nunn), [George Schultz](https://en.wikipedia.org/wiki/George_Shultz), and others with the [Nuclear Threat Initiative](https://en.wikipedia.org/wiki/Nuclear_Threat_Initiative) have said that as long as the world maintains large nuclear arsenals, it's only a matter of time before a nuclear war occurs.  The present work only makes those calls more urgent: As long as the nations of the world fail to provide effective judicial recourse to perceived threats, non-nuclear nations and terrorist groups will feel a need to obtain nuclear weapons, which become more available with the passage of time.  This article has estimated tolerance intervals for the time to the next new nuclear nation using a renewal process with log hazard for the increments being linear in the time since the first successful [Trinity test](https://en.wikipedia.org/wiki/Trinity_(nuclear_test)), 1945-07-16. 

# Appendix.  Plotting to a file 

Plotting the time between first tests to a file was surprisingly difficult, because font sizes in the files were smaller than the standard display, and getting larger fonts was surprisingly difficult.  Consider the following:

````{r png}
if(FALSE){
  png('nuclearProliferation.png', 1440, 1200)
  par(mar=c(15, 12, 4, 2)+.1)
  plot(yearsSinceLastFirstTest~firstTest, 
     nuclearWeaponStates, type='h', 
     xlab='', ylab='', las=1, cex.axis=4, 
     bty='n', axes=FALSE, lwd=2, 
     ylim=ylim.)
  xyr <- seq(1950, 2000, 10)
  xt. <- paste0(xyr, '-01-01')
  xticks <- as.Date(xt.)
  axis(1, xticks, labels=FALSE, lwd=2)
  axis(1, xticks, xyr, cex.axis=4, lwd=0, line=2)
#axis(1, seq(1950, 2000, by=10), cex.axis=4, lwd=0, line=1)
  axis(2, cex.axis=4, las=1, lwd=2)
  title('Time between new nuclear nations', 
      cex.main=4)
  mtext(paste0(
    'Note: The US is not on this plot,', 
    '\nbecause it had no predecessors.'), 
        1, 12, cex=4)
  mtext('years from the\nprevious "first test"',
      2, 5, cex=4)
  with(nuclearWeaponStates, 
    text(firstTest, yearsSinceLastFirstTest,
       ctry, xpd=TRUE, cex=4))
  dev.off()
}
```

Plot to an svg file, killing the labels for Wikimedia Commons:  

```{r svg}
if(FALSE){
  svg('nuclearProliferation.svg', 14, 11)
  Label. <- FALSE
  par(mar=c(9, 8, 4, 2)+.1)
  cex. <- 4
  plot(yearsSinceLastFirstTest~firstTest, 
     nuclearWeaponStates, type='h', 
     xlab='', ylab='', axes=FALSE, 
     bty='n', ylim=ylim.)
#  axis(1, cex.axis=cex., line=1)
  axis(1, labels=FALSE)
  axis.Date(1,
    nuclearWeaponStates$firstTest, 
    tick=FALSE, cex.axis=cex., line=2)
  axis(2, cex.axis=cex., las=1)
  if(Label.)title(
    'Time between new nuclear nations',
                  cex.main=2)
  noUS <- paste0(
    'Note: The US is not on this plot,', 
    '\nbecause it had no predecessors.')
  if(Label.)mtext(noUS, 1, 6, cex=cex.)
  ylab. <- paste(
    'years from the\nprevious "first test"')
  if(Label.)mtext(ylab., 2, 4, cex=cex.)
  with(nuclearWeaponStates, 
    text(firstTest, yearsSinceLastFirstTest,
       ctry, xpd=TRUE, cex=cex.))
  dev.off()
}
```

Plot to png, killing the labeling for Wikimedia Commons

````{r png2}
ymax <- max(nuclearWeaponStates$yearsSinceLastFirstTest, 
            na.rm=TRUE)
ylim. <- c(0, ymax)

png. <- FALSE
cex.ax=1 
lbl <- TRUE
if(png.){ 
    png('nuclearProliferation.png', 1440, 1200)
  if(lbl){
#    par(mar=c(15, 15, 7, 2)+.1)
    par(mar=c(15, 15, 2, 2)+.1)
  } else par(mar=c(5, 5, 2, 2)+.1)
    cex.ax=4
}
plot(yearsSinceLastFirstTest~firstTest, 
     nuclearWeaponStates, type='h', 
     xlab='', ylab='', las=1, cex.axis=cex.ax, 
     bty='n', axes=FALSE, lwd=2, ylim=ylim.)
if(lbl){
#  title('Figure 1. Time between\nnew nuclear nations', 
#    cex.main=cex.ax)
  xlab. <- paste(c('Note: The US is not on this plot,',
                   'because it had no predecessors.'), 
                 collapse='\n')
  mtext(xlab., 1, 11, cex=cex.ax)
  mtext('years from the\nprevious "first test"',
        2, 6, cex=cex.ax)
}
xyr <- seq(1950, 2000, 10)
xt. <- paste0(xyr, '-01-01')
xticks <- as.Date(xt.)
axis(1, xticks, labels=FALSE, lwd=2)
axis(1, xticks, xyr, cex.axis=cex.ax, lwd=0, line=2)
#axis(1, seq(1950, 2000, by=10), cex.axis=4, lwd=0, line=1)
axis(2, cex.axis=cex.ax, las=1, lwd=2)
#  title('Time between new nuclear nations', cex.main=4)
xlab. <- paste0('Note: The US is not on this plot,', 
    '\nbecause it had no predecessors.')
#  mtext(xlab., 1, 12, cex=4)
ylab. <- paste0('Note: The US is not on this plot,', 
    '\nbecause it had no predecessors.')
#  mtext(ylab., 1, 12, cex=4)
  
with(nuclearWeaponStates, 
    text(firstTest, yearsSinceLastFirstTest,
       ctry, xpd=TRUE, cex=cex.ax))
if(png.) dev.off()

```


# Predictions using the actual increments in the MCMC simulations




# References

[^India]: [India had military conflicts with China in 1962 and 1967](https://en.wikipedia.org/wiki/China%E2%80%93India_relations) before India's first nuclear weapon's test 1974-05-18.  India and China have continued to have conflicts, including, e.g., [the Doklam standoff in 2017](https://en.wikipedia.org/wiki/2017_China%E2%80%93India_border_standoff).

[^Pak]: [India-Pakistan relations](https://en.wikipedia.org/wiki/India%E2%80%93Pakistan_relations) have been marked by frequent conflict since the two nations were born with the dissolution of the British Raj in 1947.  This history might help people understand the need that Pakistani leaders may have felt and still feel for nuclear parity with India. 

[^Israel]: [Israel faced many threats from its Arab neighbors before it became an independent nation in 1949](https://en.wikipedia.org/wiki/Arab%E2%80%93Israeli_conflict). These have continued, including the [Gaza border protests](https://en.wikipedia.org/wiki/2018_Gaza_border_protests) that have continued at least to mid 2019.  One might therefore reasonably understand why Israel might feel a need for nuclear weapons and why others might believe that the 1979-09-22 [Vela incident](https://en.wikipedia.org/wiki/Vela_Incident) was an Israeli nuclear test. 

[^quickNukes]: In addition to the 32 currently non-nuclear-weapon states with "sufficient fissile material to make nuclear weapons if they wished", per @Toon:2007, the inspector general of the US Department of Energy concluded in 2009 (in its most recent public accounting) that enough highly enriched uranium was missing from US inventories to make at least five nuclear bombs comparable to those that destroyed substantial portions of Hiroshima and Nagasaki in 1945.  Substantially more weapons-grade materials may be missing in other countries, especially Russia (@Malone:2018).   

[^ranWalk]: The [`bssm` package](https://www.rdocumentation.org/packages/bssm/versions/0.1.7) provides a reasonable framework for modeling this.  Its [`ng_bsm` function](https://www.rdocumentation.org/packages/bssm/versions/0.1.7/topics/ng_bsm) supports modeling a normal random walk in log(Poisson mean) of the number of "first tests" each year with the log(Poisson mean). This uses the fact that [the probability distribution of the time between events in a Poisson point process is exponential](https://en.wikipedia.org/wiki/Exponential_distribution).   

[^WikivTime]: For precursors to the current study that involve censored estimation of time to a nuclear war, see @Wikiv:extinct and @Wikiv:Armageddon.  