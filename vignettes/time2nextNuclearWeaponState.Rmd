---
title: "Time to next new nuclear-weapon state"
author: "Spencer Graves"
date: "2019-12-21"
output: bookdown::pdf_book
#output: bookdown::gitbook
#NOTE:  As of 2019-11 "Figure \@ref(fig:plot)" 
# does not work with 
# output: html_document 
bibliography: nuc-references.bib
vignette: >
  %\VignetteIndexEntry{Time to next new nuclear-weapon state}
  %\VignetteKeyword{nuclear-weapon states}
  %\VignetteEngine{knitr::knitr}
  %\SweaveUTF8
  \usepackage[utf8](inputenc)
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Abstract

This article models the time between the "first test" of a nuclear weapon by one nation and the next.  It uses this model to obtain confidence bounds on the number of nuclear-weapon states decades into the future.  A plot of the times between "first tests" of the 9 nuclear powers as of 2019-10-15 suggests a nonhomogeneous [renewal process](https://en.wikipedia.org/wiki/Renewal_theory) that suggests a linear decrease in time in log(Poisson mean) of the number of first tests each year by new nuclear-weapon states).  This can be modeled using [`glm(..., family=poisson)`](https://www.rdocumentation.org/packages/stats/versions/3.6.1/topics/glm).  We fit this model and use it to predict the probabilities of further nuclear proliferation.    
  
# Introduction 

The plot of times between "first tests" by the world's nuclear-weapon states as of 2019-05-14 suggests that the process of nuclear proliferation has slowed over time;  see Figure \@ref(fig:plot). 

```{r, plot, fig.cap = "Time between new nuclear-weapon states"}
library(Ecdat)
data(nuclearWeaponStates)
ymax <- max(
  nuclearWeaponStates$yearsSinceLastFirstTest, 
            na.rm=TRUE)
ylim0 <- c(0, ymax)

plotNucStates <- function(type.='n', xlim., ylim., 
    line.=3:2, cex.=1, mtext.=TRUE, log.='', ...){
##
## Write a function to create this desired plot
## that is general enough to be customized 
## to make other similar but different plots 
## later.  
## 
## Obviously, during the process of writing 
## this vignette, it requires revising this 
## function later as the needs become clearer.  
##  
## The advantage of doing it this way, it that
## it makes the code easier to read, because 
## it's clearer it clearer what is the same and 
## what is different between similar plots.  
##
#   Start with an internal function 
#   to add the 2-letter country codes.     
  addCountries <- function(line.=3:2, cex.=1, mtext.=TRUE){
#  Add the country codes ("ctry") to a plot 
#  showing the time between "first tests" 
#  of nuclear-weapon states
# ... to save copying code 
#  and hopefully make the logic clearer
    xlab. <- paste(c(
        'Note: The US is not on this plot,',
        'because it had no predecessors.'), 
               collapse='\n')
    if(mtext.){
        mtext(xlab., 1, line.[1], cex=cex.)
        mtext('years from the\nprevious "first test"',
        2, line.[2], cex=cex.)
    }
    with(nuclearWeaponStates, 
        text(firstTest, yearsSinceLastFirstTest,
          ctry, xpd=TRUE, cex=cex.))
  }
#  xlim and ylim?
  if(missing(xlim.))xlim. <- range(
    nuclearWeaponStates$firstTest)
  if(missing(ylim.))ylim. <- range(
    nuclearWeaponStates$yearsSinceLastFirstTest[-1])
#  
  plot(yearsSinceLastFirstTest~firstTest, 
       nuclearWeaponStates, type=type., 
       xlab='', ylab='', las=1, 
       xlim=xlim., ylim=ylim., log=log., bty='n', 
       ...)
  addCountries(line.=line., cex.=cex., mtext.=mtext.)
}    
plotNucStates(type.='h', ylim.=ylim0)
```

However, it stretches credibility to suggest that nuclear proliferation has stopped.  There were only 5 nuclear-weapon states when the [Treaty on the Non-Proliferation of Nuclear Weapons (NPT, Non-proliferation treaty)](https://en.wikipedia.org/wiki/Treaty_on_the_Non-Proliferation_of_Nuclear_Weapons) entered into force in 1970.  When US President [George W. Bush](https://en.wikipedia.org/wiki/George_W._Bush) decried an ["Axis of evil"](https://en.wikipedia.org/wiki/Axis_of_evil) in his State of the Union message, 29 January 2002, there were 8.  As this is written 2019-10-15, there are 9.  @Toon:2007 noted that in 2003 another 32 had sufficient fissile material to make nuclear weapons if they wished.  

Moreover, those 32 do NOT include either Turkey nor Saudi Arabia.  On September 4, 2019, Turkish President Erdogan said it was unacceptable for nuclear-armed states to forbid Turkey from acquiring its own nuclear weapons.^[@Toksabay:2019; @OConnor:2019] 

In 2006 *Forbes* reported that Saudi Arabia has "a secret underground city and dozens of underground silos for" Pakistani nuclear weapons and missiles.^[@Forbes:SaudiNuc;  see also @Wikip:SaudiNuc.] In 2018 the *Middle East Monitor* reported that "Israel 'is selling nuclear information' to Saudi Arabia".^[@MEM:SaudiNuc;  see also @Wikip:SaudiNuc.]  This is particularly disturbing, because of the substantial evidence that Saudi Arabia may have been and may still be the primary recruiter and funder of Islamic terrorism.^[@Benjamin:2016; see also @Wikiv:WinTerror]  

This analysis suggests that the number of nuclear-weapon states will likely continue to grow until either (i) a nuclear war destroys the ability of anyone to make more nuclear weapons, or (ii) the fundamental structure of international relations changes to the point that any nation that perceives an external threat can confidently rely on international law for protection, without a military that might threaten other countries.

This vignette first reviews the data and history on this issue including brief discussions of what might have motivated different nations to pursue nuclear weapons.  We then consider modeling these data as a series of annual Poisson observations of the number of states conducting a first test of a nuclear weapon each year (1 in each of 8 years since 1945; 0 in the others).  

The simplest such model that considers the possible inhomogeniety visible in Figure \@ref(fig:plot) is [Poisson regression](https://en.wikipedia.org/wiki/Poisson_regression) assuming that log(Poisson mean) is linear in the time since the first test of nuclear weapon by the US in 1945.  We estimate this using [`glm(..., family=poisson)`](https://www.rdocumentation.org/packages/stats/versions/3.6.1/topics/glm).  This model is plausible to the extent that this trend might represent a growing international awareness of the threat represented by nuclear weapons including a hypothesized increasing reluctance of existing nuclear-weapon stated to share their technology. The current process of ratifying the [Treaty on the Prohibition of Nuclear Weapons](https://en.wikipedia.org/wiki/Treaty_on_the_Prohibition_of_Nuclear_Weapons) supports the hypothesis of such a trend, while the lack of universal support for it clearly indicates that nuclear proliferation is still likely to continue.  We use this model to extend the 74 years of history of nuclear proliferation available as this is being written in 2019 into predicting another 74 years into the future. First, however, we review some of the history that may have motivated existing nuclear-weapon states to develop this techology.  

# What motivated the existing nuclear-weapon states to develop this capability?

@Ellsberg:2017 noted that every US president since [Truman (president: 1945-1953)](https://pl.wikipedia.org/wiki/Harry_Truman) considered the use of nuclear weapons.  [With the possible exception of Ford, all threatened to use them, sometimes publicly, sometimes in secret.](https://en.wikipedia.org/wiki/Daniel_Ellsberg#The_Doomsday_Machine)  Countries threatened include the Soviet Union (now Russia), the People's Republic of China, Iraq, Iran, Libya, India, and North Korea.  

One might therefore understand the motivation of North Korea to accelerate their nuclear program in the early 2000s after hearing themselves along with Iran and Iraq described as the ["Axis of evil"](https://en.wikipedia.org/wiki/Axis_of_evil) by US President [George W. Bush](https://en.wikipedia.org/wiki/George_W._Bush) and after then seeing Iran repeatedly threatened and Iraq invaded with [estimated deaths ranging from over 100,000 to over a million](https://en.wikipedia.org/wiki/Iraq_War) out of a population in 2016 of roughly 37 million.  Indeed, any reasonable person might understand the eagerness of North Korean leaders for something that could protect them from similar threats.  

Similar logic might explain why Soviet leaders might have felt a need to defend themselves from nuclear coercion after [having been invaded by the US and over a dozen other countries trying to put the Tsar back in power after World War I](https://en.wikipedia.org/wiki/Allied_intervention_in_the_Russian_Civil_War).  The United Kingdom and France likely felt nuclear threats from the Soviet Union.  China faced nuclear threats from the US regarding Korea and the Taiwan Strait.  India faced major threats from China, [^India] Pakistan from India,[^Pak] and Israel from its neighbors.[^Israel]

More generally the history of US belicosity includes [invading Canada in 1812](https://www.history.com/news/how-u-s-forces-failed-to-conquer-canada-200-years-ago)^[@Berton:1980] and [numerous other foreign interventions](https://en.wikipedia.org/wiki/Foreign_interventions_by_the_United_States) including invading [Afghanistan in 2001](https://en.wikipedia.org/wiki/War_in_Afghanistan_(2001%E2%80%93present)), and [Iraq in 2003](https://en.wikipedia.org/wiki/Iraq_conflict_(2003%E2%80%93present)), plus continued threats against Iran, North Korea, and now Venezuela.  This history might help people understand how leaders in many countries may be concerned about their own security if they fail to do what the US demands of them.  The [extra-judicial execution of Osama bin Laden and four others in his household by SEAL Team 6](https://en.wikipedia.org/wiki/Death_of_Osama_bin_Laden) on 2011-05-02 has reportedly increased the risks that a Pakistani nuclear weapon might be stolen by Islamic terrorists intent on retaliating against the US for its interventions in Pakistan and neighboring countries.^[@Cohen:2009;  see also @Borger:2010] 

\vspace{\baselineskip}
\centerline{\textit{\textbf{The September 11th attacks}}}

\centerline{\textit{\textbf{might have been a mushroom cloud.}}}
\vspace{\baselineskip}

In this context, declassified US government documents establish that in the 1980s, when the US was clandestinely supporting the Contra war against Nicaragua in violation of US law, it was also [secretly helping the Pakistani nuclear program in violation of US law.  This was done to secure Pakistani cooperation with US support for anti-Soviet resistance in Afghanistan](https://www.wilsoncenter.org/publication/new-documents-spotlight-reagan-era-tensions-over-pakistani-nuclear-program).^[@Burr:2012, @Burr:2013] 

Without this, "the nuclear weapons programmes of Iran, Libya and North Korea - which British and American intelligence now acknowledge were all secretly enabled by Pakistan - would never have got off the ground," according to [Robert Gallucci](https://en.wikipedia.org/wiki/Robert_Gallucci), special adviser on WMDs to President Clinton.^[The quote is from @Levy:2007.   That article claims he was a special adviser on WDMs to both Clinton and G. W. Bush.  However, the Wikipedia article and @Gallucci:2001 both indicate he left government service in January 2001;  G. W. Bush took office 2001-01-20.]  

Similar comments have been made by [Richard Barlow](https://en.wikipedia.org/wiki/Richard_Barlow_(Intelligence_analyst)#cite_note-wp-1), a CIA analyst who reported these questionable activities to a committee of the US House.^[@Levy:2007. Barlow was reportedly severely punished for honestly answering questions in a classified briefing to an oversight committee of the US House.  Barlow described US assistance to Pakistan's nuclear weapons program in exchange for Pakistan's help in supplying rebels in Afghanistan fighting Soviet occupation.  This was during the [Iran-Contra affair](https://en.wikipedia.org/wiki/Iran%E2%80%93Contra_affair), which exposed actions of officials of the Reagan administration to pursue foreign policy objectives in Central America in blatant violation of law passed by Congress and signed by the President.]

And now the US is helping Saudi Arabia obtain nuclear power, in spite of (a) the evidence that [the Saudi government including members of the Saudi royal family were  involved in preparations for the suicide mass murders of September 11, 2001, at least as early as 1999](https://en.wikipedia.org/wiki/The_28_pages) and (b) their [on-going support for Al Qaeda in Yemen, reported as recently as 2019](https://en.wikipedia.org/wiki/Saudi_Arabian-led_intervention_in_Yemen). 

**Conclusions**:  
 
  1. There seems to be no shortage of motivations for other countries to acquire nuclear weapons.  
  
  2. The knowledge and materials required to make such weapons in a relatively short order are also fairly widely available, even without the documented willingness of current nuclear powers to secretly help other countries acquire such weapons.[^quickNukes]  
  
  3. Unless there is some fundamental change in the structure of international relations, it seems unwise to assume that there will not be more nuclear nations in the future, with the time to the next "first test" of a nuclear weapon following a probability distribution consistent with the previous times between "first tests" of nuclear weapons by the current nuclear-weapon states.  

# Exponential time between Poisson 'first tests' 

Possibly the simplest model for something like the time between 'first tests' in a situation like this is to assume they come from one [exponential distribution](https://en.wikipedia.org/wiki/Exponential_distribution) with 8 observed times between the 9 current nuclear-weapon states plus one [censored observation](https://en.wikipedia.org/wiki/Censoring_(statistics)) of the time between the most recent one and a presumed next one.[^WikivTime]  

However, Figure \@ref(fig:plot) suggests that the time between 
'first tests' of succeeding nuclear-weapon states is increasing.  This makes it difficult to use censored data estimation as just described.  

To understand the current data better, we redo Figure \@ref(fig:plot) with a log scale on the y axis in Figure \@ref(fig:ploty).   

```{r ploty, fig.cap = "Time between new nuclear-weapon states"}
plotNucStates(log.='y')
```

Figures \@ref(fig:plot) and \@ref(fig:ploty) seem consistent with the following:

- Time between events might be exponentially distributed but with a hazard rate that varies over time.  [Recall that the [hazard rate](https://en.wikipedia.org/wiki/Survival_analysis#Hazard_function_and_cumulative_hazard_function) for the exponential distribution is constant: $h(t) = (-d/dt \log S(t)) = \lambda$, writing the exponential survival function as $S(t) = \exp(-\lambda t)$.]  This is consistent with the apparent increase in the time to the next "first test" by a new nuclear-weapon state.  
- Even though nuclear proliferation has been slowing since 1950, it could _accelerate_ in the future if more states began to perceive greater threats from other nations.  
- Log hazard that is either linear in the time since the first test of a nuclear weapon, code-named ["Trinity"](https://en.wikipedia.org/wiki/Trinity_(nuclear_test)), or behaves like a ["Wiener process" (also called a "Brownian motion")](https://en.wikipedia.org/wiki/Wiener_process), which means that the variance of the increments in log(hazard) between "first tests" is proportional to the elapsed time.  In this article, we model the trend as linear and leave consideration of a [Gaussian random walk](https://en.wikipedia.org/wiki/Random_walk) and similar stochastic formulations for future work.[^ranWalk]

Because of the well-known duality between the [exponential distribution](https://en.wikipedia.org/wiki/Exponential_distribution) and the [Poisson distribution](https://en.wikipedia.org/wiki/Poisson_distribution), we can also model this as a series of the number of events each year, month, week, or day.  For present purposes, we will use a series of annual observation.  Changing to monthly, weekly or daily observations might give us slightly better answers while possibly increasing the compute time more than it's worth.  

# Parameter estimation 

For modeling and parameter estimation, we use [`glm(firstTests ~ timeSinceTrinity, poisson)`](https://www.rdocumentation.org/packages/stats/versions/3.6.1/topics/glm) with:   

- `firstTests` = the number of first tests of a nuclear-weapon by a new nuclear-weapon state each year, and   
- `timeSinceTrinity` = number of years since 1945-07-16, when the first nuclear weapon was tested, code-named ["Trinity"](https://en.wikipedia.org/wiki/Trinity_(nuclear_test)).  

We use the [`lubridate` package](https://lubridate.tidyverse.org/) for dates.  The first thing we want is the current year.  We get that starting with [`today`](https://www.rdocumentation.org/packages/lubridate/versions/1.7.4/topics/today):  

```{r today}
library(lubridate)
(Today <- today())
```

From this we get the year:  

```{r year}
(currentYear <- year(Today))
```

Let's include an observation for the current year only if it's more than 6 months since January 1 and since the last "first test":  

```{r currentYear}
if((month(Today)<7) || 
   (difftime(Today, 
          tail(nuclearWeaponStates$firstTest, 1), 
          units = 'days')<(366/2)))
      currentYear <- (year(Today)-1)
```

Start after the year of the first test of a nuclear weapon:  

```{r firstYear}
firstTstYr <- year(nuclearWeaponStates$firstTest)
(firstYear <- firstTstYr[1])
```

Now let's create a vector of the number of "firstTests" by year:  

```{r firstTests}
(nYrs <- currentYear - firstYear)
firstTests <- ts(rep(0, nYrs), firstYear+1)
firstTstYrSinceFirst <- firstTstYr - firstYear
firstTests[firstTstYrSinceFirst] <- 1

library(tibble)
#(FirstTsts <- tibble(Year=time(firstTests), 
#      nFirstTests=as.numeric(firstTests)))
(FirstTsts <- tibble(Year=time(firstTests), 
      nFirstTests=firstTests))
```

Add `ctry` to this tibble:  

```{r firstCtry}
Ctry <- rep('', nYrs)
Ctry[firstTstYrSinceFirst] <- 
        nuclearWeaponStates$ctry[-1]
FirstTests <- cbind(FirstTsts, ctry=Ctry)
```

And add `timeSinceTrinity`:  

```{r timeSince}
FirstTests$timeSinceTrinity <- 1:nYrs
```

Now fit this model:  

```{r fit1}
summary(PoissonFit <- glm(
  firstTests ~ timeSinceTrinity, 
  poisson, FirstTests))
```

This says that the time trend visible in Figures \@ref(fig:plot) and \@ref(fig:ploty) is not statistically significant.  

[George Box](https://en.wikipedia.org/wiki/George_E._P._Box) famously said that, ["All models are wrong, but some are useful."](https://en.wikipedia.org/wiki/All_models_are_wrong#Historical_antecedents) 

@Burnham:1998 and others claim that better predictions can generally be obtained using Bayesian Model Averaging.^[See also @Burnham:2002 and Claeskens:2008.] In this case, we have two models:  `log(Poisson mean)` being constant or linear in `timeSinceTrinity`.  The [`bic.glm`](http://finzi.psych.upenn.edu/R/library/BMA/html/bic.glm.html) in the [`BMA`](http://finzi.psych.upenn.edu/R/library/BMA/html/bic.glm.html) package can estimate these two models for us and compute the posterior probabilities as follows:  

```{r BMA}
library(BMA)
fitProlif <- bic.glm(
  FirstTests['timeSinceTrinity'], 
  FirstTests$nFirstTests, 
  "poisson")
summary(fitProlif)
```

It is standard in the BMA literature to assume an approximate uniform distribution over all models considered with a penalty for estimating each additional parameter to correct for the tendancy of the models to overfit the data.  With these standard assumptions, this comparison of these two models estimates a `r round(100*fitProlif$postprob[2], 1)` percent posterior probability for model including `timeSinceTrinity`, leaving `r round(100*fitProlif$postprob[2], 1)` percent probability for the model with constant Poisson mean.  Figure \@ref(fig:plotyf) adds these lines to Figure \@ref(fig:ploty).   

```{r plotyf, fig.cap = "BMA fit to time between new nuclear-weapon states"}
plotNucStates(log.='y')

predProlif <- with(fitProlif, 
    outer(rep(1, nYrs+1), mle[, 1]) + 
    outer(0:nYrs, mle[, 2]))
lgnd <- paste0(c('constant', 'linear'), 
    ' (', 100*round(fitProlif$postprob, 2), '%)')
firstTest_nYrs <- as.Date(paste0(
  trunc(nuclearWeaponStates$firstTestYr[1])+0:nYrs, 
  '-07-01') )
matlines(firstTest_nYrs, exp(-predProlif), 
         lty=c('dashed', 'dotted'), 
         col=c('red', 'blue'))
legend('topleft', lty=c('dashed', 'dotted'), 
     col=c('red', 'blue'), lgnd, 
     bty='n')
```

The obvious bias in the lines being higher than the mean of the points and a linear trend through the points can be explained by the censoring implied by the inclusion of a dozen years with zero "first tests" since the "first test" by North Korea, 2006-10-09.  

We shall compute here central 80 percent confidence and predction intervals for future nuclear proliferation based on the fitted BMA model.  ([''Confidence intervals''](https://en.wikipedia.org/wiki/Confidence_interval) bound the predicted mean number of nuclear-weapon states for each future year considered.  [''Prediction intervals''](https://en.wikipedia.org/wiki/Prediction_interval) bound the actual number of nuclear-weapon states;  they combine the uncertainty in the Poisson process modeled with the uncertainty of estimating the mean of that process for each future year considered.)^[We could also compute $(p, 1-\alpha)$ [''tolerance intervals''](https://en.wikipedia.org/wiki/Tolerance_interval#Relation_to_other_intervals) that would have a probability of $(1-\alpha)$ of containing a proportion of at least $p$ of all future observations.  That's more than is needed for the present application.] 
  
# Confidence intervals    
  
We will start by computing `nSims` simulated Poisson mean numbers of "first tests" by new nuclear-weapon states for each of the `nYrs` years used in `fitProlif` and another `nYrs` years beyond.  These simulations will later be used to compute confidence intervals for the model fit and predictions.    

```{r meanSims}
nSims <- 5000
timeSncT <- 1:(2*nYrs)
pastfut <- tibble(Year=firstYear+timeSncT, 
                 timeSinceTrinity=timeSncT)
library(Ecfun)
simMeans <- simulate(fitProlif, nSims, seed=3, 
    newdata=pastfut['timeSinceTrinity'], type='response')
dim(simMeans)
```

Let's invert these simulated Poisson means to get simulated exponential times, then summarize them in a format compatible with `nuclearWeaponStates`: 

```{r expSum}
sumSims <- function(x, Year=pastfut$Year){
##
## return data.frame of Year with 
## mean and (.1, .5, .9) quantiles
## 
  Yr <- as.Date(paste0(Year, '-07-01'))
  xMean <- apply(x, 1, mean)
  xCI <- apply(x, 1, quantile, 
                  probs=c(.1, .5, .9))
  xSum <- data.frame(Year=Yr, 
        mean=xMean, data.frame(t(xCI)))
# fix names
  colnames(xSum)[3:5] <- c('L10', 'median', 'U10')
  xSum
}
sumExpMeans <- sumSims(1/simMeans)
```

These numbers are added to Figure \@ref(fig:ploty) to produce Figure \@ref(fig:plotfut).  

```{r plotfut, fig.cap = "Estimated mean time between first tests, past and future"}
xlim. <- range(sumExpMeans$Year)
ylim. <- range(nuclearWeaponStates$yearsSinceLastFirstTest, 
    head(sumExpMeans[-1], 1), tail(sumExpMeans[-1], 1), 
    na.rm=TRUE)

plotNucStates(xlim.=xlim., ylim.=ylim., log.='y')

with(sumExpMeans, lines(Year, mean))
with(sumExpMeans, lines(Year, median, lty='dashed', col='blue'))
with(sumExpMeans, lines(Year, U10, lty='dotted', col='red'))
with(sumExpMeans, lines(Year, L10, lty='dotted', col='red'))
legend('topleft', c('80% confidence interval for the mean', 
          'mean', 'median'),
   col=c('red', 'black', 'blue'), 
   lty=c('dotted', 'solid', 'dashed'), bty='n')
abline(h=200, lty='dotted', col='grey')
```

The fairly flat shape of the median and lower 10 percents lines seem consistent with a model that is `r 100*round(fitProlif$postprob[1], 2)` percent constant and `r 100*round(fitProlif$postprob[2], 2)` percent linear on the log scale, reported with `summary(fitProlif)` above.  The substantial curvature of the solid line forecast looks hopeful, with a mean of simulated means being almost 200 years between successive "first tests" by new nuclear-weapon states.  

However, those are simulated lognormal distributions, which means that its reciprocal will also be lognormal with the same standard deviation on the log scale.  This standard deviation is larger the farther we extrapolate into the future.  That increasing standard deviation explains how the averate or mean line in Figure \@ref(fig:plotfut) can exceed the upper 10 percent line.  It also means that the shape of the reciprocal extrapolation in log(Poisson mean) number of first tests of new nuclear-weapon states each year can be similar, but negatively skewed rather than positively skewed as in Figure \@ref(fig:plotfut).   

A more interesting and useful view of this is to plot the evolution of the number of nuclear-weapon states through the historical period followed by the forecasts per these simulations.  To compute this we first [cumsum](https://www.rdocumentation.org/packages/base/versions/3.6.2/topics/cumsum) `simMeanNucStByYr`, the simulated mean number of new nuclear-weapon states for future years.  (In doing this, we assume a zero probability of a nuclear power giving up their nuclear weapons, as [South Africa did prior to its first universal elections in 1994](https://en.wikipedia.org/wiki/South_Africa#End_of_apartheid).)  

```{r cumsum}
str(cumMeans <- apply(simMeans[-(1:nYrs), ], 
                              2, cumsum))
quantile(cumMeans[nYrs,])
(nNucStates <- nrow(nuclearWeaponStates))
str(cumCI <- sumSims(
    nNucStates+rbind(0, cumMeans), 
    pastfut$Year[-(1:(nYrs-1))]))
```

These numbers are plotted in Figure \@ref(fig:plotcum).  

```{r plotcum, fig.cap = "Number of nuclear-weapon states, past and predicted mean"}
plotNNucStates <- function(xpast=nuclearWeaponStates, 
        xfuture=cumCI, ...){       
##
## plot stairsteps for xpast and lines for xfuture
## with either 5 or 7 columns in xfuture  
##
  xlim. <- c(xpast$firstTest[1], tail(xfuture$Year, 1))
  nColsFut <- length(xfuture)
  ylim. <- c(0, tail(xfuture[[nColsFut]], 1))
  
  plot(xlim., ylim., type='n', xlab='', ylab='', las=1, 
     bty='n')
##
## 1.  plot xpast
##  
  fT_date <- c(xpast$firstTest[1], 
      xpast$firstTest, Today)
  lines(fT_date, 
      c(0:nNucStates, nNucStates), type='s')
##
## 2.  plot xfuture 
##
  with(xfuture, lines(Year, mean))
  with(xfuture, lines(Year, median, lty='dashed', col='blue'))
  with(xfuture, lines(Year, U10, lty='dotted', col='red'))
  with(xfuture, lines(Year, L10, lty='dotted', col='red'))
  ncols <- 3
  if(nColsFut>5){
    with(xfuture, lines(Year, predU10, lty='dotted', col='green'))
    with(xfuture, lines(Year, predL10, lty='dotted', col='green'))
    ncols <- 4
  }
##
## 3.  legend
##  
  leg <- c('80% confidence level for the mean', 'mean', 'median', 
           'predictions')
  col. <- c('red', 'black', 'blue', 'green')
  lty. <- c('dotted', 'solid', 'dashed', 'dashed')
    
  legend('topleft', leg[1:ncols], col=col.[1:ncols], 
         lty=lty.[1:ncols], bty='n')
}
plotNNucStates()
```  
  
The slopes of the mean and median lines are steeper than the recent history, but the statistical evidence does not support the naive interpretation of a slowing in nuclear proliferation that one might get from considering only the most recent data.  

Let's add prediction intervals to this plot.  

# Prediction intervals

The simplest bounds on the future are [prediction intervals](https://en.wikipedia.org/wiki/Prediction_interval), which combine the statistical uncertainty in the models with the random variability in the outcomes.  For this we use `rpois(., simMeanNucStByYr)`:

```{r simNew}
set.seed(9)
simPred <- data.frame(lapply(
    simMeans[-(1:nYrs),], rpois, n=nYrs))
cumPred <- data.frame(lapply(
    simPred, cumsum))

str(cumPI <- sumSims(  
    nNucStates+rbind(0, cumPred),
    pastfut$Year[-(1:(nYrs-1))]))
names(cumPI)[c(3, 5)] <- paste0(
          'pred', c('L', 'U'), 10)
cumC.PI <- cbind(cumCI, cumPI[c(3, 5)])
```

We add this to the image in Figure \@ref(fig:plotcum) to create Figure \@ref(fig:plotPred).    

```{r plotPred, fig.cap = "Number of nuclear-weapon states, past and predicted"}
plotNNucStates(xfuture=cumC.PI)       
```  

We also plot the probability of further nuclear proliferation by summarizing `simCumNewNucSt` in Figure \@ref(fig:prolif).    

```{r prolif, fig.cap = "Probability distribution of the  time to the next 1:5 new nuclear-weapon states"}
plotProbs <- function(x=cumPred, 
    adj.=matrix(c(.53, -.4, .55, 1.15), 2, byrow=TRUE), 
    ...){ 
##
## Probability distribution of the next 1:5 
## new nuclear-weapon states 
##
## from x = cumPred, a data.frame
##  
  maxNewNucSt <- 5
  probs <- function(x, n=maxNewNucSt){
    p <- colMeans(outer(x, 0:(n-1), '>'))
    p
  }
  probProlif. <- apply(as.matrix(x), 1, probs)
  probProlif <- ts(t(probProlif.), 
                     currentYear+1)

  matplot(time(probProlif), probProlif, 
        type='l', xlab='', las=1, ylab='', ylim=0:1, 
        ...)
  for(i in 1:maxNewNucSt){
    it <- min(which(probProlif[,i]>=0.5))
#    cat(time(probProlif)[it], '')
    text(time(probProlif)[it], 0.5, 
       paste0(time(probProlif)[it], '\n', i))
  }
  abline(h=.5, lty='dotted')

  text(time(probProlif)[it]+16, 0.5, 
      'median year for', adj=adj.[1,])
  text(time(probProlif)[it]+13, 0.5, 
      'more nuclear-\nweapon states', 
           adj=adj.[2,])
}
plotProbs()
```

The image in Figure \@ref(fig:prolif) seems too pessimistic to be credible if we believe that nuclear proliferation has slowed.  This is suggested by all the above figures, but was not statistically significant in the `glm` model `PoissonFit` above.  This encouraged us to use Bayesian Model Averaging (BMA), which placed more weight on the constant model.  

To get more optimistic estimates, we need to assume that nuclear proliferation has slowed more than is supported by the model fitting above. One approach might be to pretend that the model `PoissonFit` above has 100 percent posterior probability rather than the mere `r round(fitProlif$postprob[2], 2)*100` computed with `fitProlif`.  As before, we start with simulations.  

```{r PoissonLin}
simulate.glm <- function(object, nsim = 1, 
        seed = NULL, newdata=NULL, 
        type = c("link", "response"), ...){
##
##  simulate method for glm objects 
##  return type='response', as used above for bic.glm 
##
##  
## 1.  seed?
##  
# copy code from stats:::simulate.lm  
  if (!exists(".Random.seed", envir = .GlobalEnv, inherits = FALSE)) 
    runif(1)
  if (is.null(seed)) 
    RNGstate <- get(".Random.seed", envir = .GlobalEnv)
  else {
    R.seed <- get(".Random.seed", envir = .GlobalEnv)
    set.seed(seed)
    RNGstate <- structure(seed, kind = as.list(RNGkind()))
    on.exit(assign(".Random.seed", R.seed, envir = .GlobalEnv))
  }
##
## 2.  newdata?
##
  if(is.null(newdata))stop('newdata required.')
  newMat <- model.matrix(~., newdata)
##
## 3.  simulate coefficients
##  
  coefLin <- coef(object)
  covLin <- vcov(object)
  simCoef <- mvtnorm::rmvnorm(nSims, coefLin, covLin)
##
## 4.  simLink 
##
  simLink <- tcrossprod(newMat, simCoef)
##
## 5.  linkinv
##
  cl <- as.list(object[['call']])
  fam <- cl[['glm.family']]
#  convert fam to the form required by glm.fit 
  family <- get(as.character(fam), 
      mode = "function", envir = parent.frame())
  if (is.function(family)) 
    family <- family()
  if (is.null(family$family)) {
    print(family)
    stop("'family' not recognized")
  }
  
## 
## 6.  return type(s) desired 
##
  if(length(type)>1){
    out <- list(link=data.frame(sims), 
        response = data.frame(linkinv(sims)))
  } else {
    tp <- match.arg(type)
    if(tp=="link"){
      out <- data.frame(sims)
    } else out <- data.frame(linkinv(sims))
  }
  attr(out, 'seed') <- RNGstate
  out
}
simMeans1 <- simulate.glm(PoissonFit, nSims, seed=3, 
    newdata=pastfut['timeSinceTrinity'], type='response')

#(coefLin <- coef(PoissonFit))
#(covLin <- vcov(PoissonFit))
#str(simLin <- mvtnorm::rmvnorm(nSims, coefLin, covLin))
#str(simMeanLin <- simLin[, 1] + 
#      outer(simLin[, 2], pastfut$timeSinceTrinity))
```

These numbers are added to Figure \@ref(fig:ploty) to produce Figure \@ref(fig:plotfut1), comparable to Figure \@ref(fig:plotfut), assuming the linear model had 100 percent of the posterior probability, not just `r round(fitProlif$postprob[2], 2)*100` percent.  

```{r plotfut1, fig.cap = "Estimated mean time between first tests with log-linear model"}
str(simMeanL1 <- apply(exp(-simMeanLin), 2, mean))
str(simMeanQtl <- exp(-t(apply(simMeanLin, 2, quantile, 
              probs=c(.1, .5, .9))) ))

yli1 <- range(
  nuclearWeaponStates$yearsSinceLastFirstTest, 
  simMeanL1, simMeanQtl, na.rm=TRUE)

op <- par(mar=c(5, 5, 4, 2)+0.1)

plotNucStates(xlim.=xlim., ylim.=yli1, 
    line.=c(3, 2.5), log.='y')

#plot(xlim., yli1, type='n', xlab='', ylab='', las=1, 
#     log='y', bty='n')
#addCountries(line=c(3, 2.5))
#mtext(paste(
#'Note: The US is not on this plot,', 
#        '\nbecause it had no predecessors.'), 1, 3)
#mtext('years from the\nprevious "first test"', 2, 2.5)
#with(nuclearWeaponStates, 
#  text(firstTest, yearsSinceLastFirstTest,
#       ctry, xpd=TRUE))
lines(expCI$estDate, simMeanL1)
lines(expCI$estDate, simMeanQtl[, 2], lty='dashed', col='blue')
matlines(expCI$estDate, simMeanQtl[, c(1, 3)], lty='dotted', col='red')
legend('topleft', c('80% confidence interval for the mean', 
          'mean', 'median'),
   col=c('red', 'black', 'blue'), 
   lty=c('dotted', 'solid', 'dashed'), bty='n')
abline(h=200, lty='dotted', col='grey')
par(op)
```

This model intuitively seems more consistent with the data, though to find it plausible, we need to supply additional intuition based on the hope or belief that nuclear proliferation is slowing and will continue to slow more than is supported by our naively preferred BMA model, `fitProlif`.  

Figure \@ref(fig:proli1) provides the same analysis of Figure \@ref(fig:prolif) for this simpler model with the log(Poisson mean) linear in time.  

```{r proli1, fig.cap = "Probability distribution of the  time to the next 1:5 new nuclear-weapon states for the glm model"}




str(probProli1. <- t(apply(exp(simMeanLin[, -(1:nYrs)]), 2, probs)))
head(probProli1.)
str(probProli1 <- ts(probProli1., currentYear+1))

matplot(time(probProli1), probProli1, 
        type='l', xlab='', las=1, ylab='', ylim=0:1)
for(i in 1:maxNewNucSt){
  it <- min(which(probProli1[,i]>=0.5))
  cat(time(probProli1)[it], '')
  text(time(probProli1)[it], 0.5, 
       paste0(time(probProli1)[it], '\n', i))
}
abline(h=.5, lty='dotted')

text(time(probProli1)[it]+16, 0.5, 
    'median year for', adj=c(.5, -.4))
text(time(probProli1)[it]+13, 0.5, 
    'more nuclear-\nweapon states', 
           adj=c(.5, 1.15))
```





str(simMeanExp <- exp(-simMeanLin))

str(expMean1 <- apply(simMeanExp, 2, mean))
str(expCI1 <- t(apply(simMeanExp, 2, quantile, 
                    probs=c(.1, .5, .9))))
head(expCI1)
colnames(expCI1) <- c('L10', 'median', 'U10')
```











Is there evidence to support a slowing in nuclear proliferation?  On the one hand, the present authors have no documentation that existing nuclear powers are actively supporting nuclear proliferation today like the US and China helped Pakistan in the 1980s.^[



] However, the documentation of that support was highly classified at the time and only became genearally available years later.  Moreover, as noted above, there are credible claims that Pakistan helped Iran and North Korea with their nuclear programs.^[ 


] As this is written in December 2019, the US is engaged in the longest war in its history (in Afghanistan) with no end in sight, and there has been precious little research to obtain honest anwers to US President George W. Bush's famous question, "Why do they hate us?"  

However, we know that, for example, [Osama bin Laden](https://en.wikipedia.org/wiki/Osama_bin_Laden) was executed without a fair trial, and that fact is reportedly deeply resented in Pakistan.  Xenophobic violence has increased in recent years the world over,^[


] reportedly driven in part by changes in the structure of the mainstream media, including for-profit structure of social media, especially Facebook.^[



] Xenophobia is stoking serious military skirmishes between two nuclear-weapon states, India and Pakistan.^[


] The slowing in the rate of nuclear visible in Figure \@ref(fig:plotcum) could be more apparent than real.  

On the other hand, the recent progress with the [Treaty on the Prohibition of Nuclear Weapons](https://en.wikipedia.org/wiki/Treaty_on_the_Prohibition_of_Nuclear_Weapons#Parties_and_signatories) is hopeful.  However, that treaty by itself seems unlikely to have any more impact on nuclear proliferation than has the [Non-Proliferation Treaty, which entered into force in 1970.](https://en.wikipedia.org/wiki/Treaty_on_the_Non-Proliferation_of_Nuclear_Weapons)  Wishful thinking will not slow nuclear proliferation.  




But the uncertainty documented in Figure \@ref(fig:plotcum) is only the statistical uncertainty in the estimates of the mean of an assumed [Poisson process](https://en.wikipedia.org/wiki/Poisson_point_process) for nuclear proliferation. In the next section, we simulate Poisson processes driven by each simulated trajectory summarized in Figure \@ref(fig:plotcum).  







```

Note that 'alpha' here is the log(Poisson mean) of the expected number of first tests each year by a new nuclear-weapon state.  That's labeled in the scale on the left of this plot.  The raw numbers were exponentiated to get the Poisson mean, then plotted on a log scale, which is the standard scale for modeling Poisson rates like this. 

The reciprocal of the Poisson mean in a context like this is the mean time (number of years) to the next event, being the expected number of years to the next "first test" by a new nuclear-weapon state.  (If the Poisson mean were constant, [the probability distribution of the time to the next event would be exponential](https://en.wikipedia.org/wiki/Exponential_distribution).)

I'd like to superimpose the actual data from `nuclearWeaponStates` as plotted above on a log scale. However, the dates above are of class `Date`, which are numbers of days since 1970-01-01.  However, for this plot the horizontal axis is in numbers of years.  For this, we use column `firstTestYr` rather than `firstTest`.  The numbers are essentially the same, except that `firstTest` is of class "Date", being numbers of days since 1970-01-01, while `firstTestYr` gives essentially the same number in years and fractions in the [Common Era (CE)](https://en.wikipedia.org/wiki/Common_Era#History_of_the_use_of_the_CE/BCE_abbreviation).  

 {r numericYears, fig.cap="Time to next 'first test' by a new nuclear-weapon state"}
mainExp <- paste("Time to next first test by a new", 
    "nuclear-weapon state")

ts.plot(1/VLU, 1/firstTstsQuant, 
    col=c(2, 5, 5, 3, 4, 3), 
    lty=c(1, 3, 3, 2, 2, 2), log='y', 
    gpars=list(las=1), xlab='', 
    ylab="years to next 'first test'")
#,main=mainExp)

legend('topleft', 
  legend=c('mean', 
    '95% CI (normal approx)', 
    'median', 
    '95% CI (MCMC)'), 
  col=c(2, 5, 4, 3), 
  lty=c(1, 3, 2, 2), bty='n')
abline(h=c(5, 10, 20), lty=2)

# plot actual points 

with(nuclearWeaponStates, 
  text(firstTestYr, yearsSinceLastFirstTest, 
       ctry, xpd=TRUE))

1/VLU[1, ]
1/tail(VLU, 1)
apply(1/VLU, 2, quantile, 
      probs=c(0, .025, .5, .975, 1))
```  

The result is available in Figure \@ref(fig:numericYears). 

This seems consistent with the plot of the data above:  There were 8 'first tests' by a new nuclear-weapon state in the 74 years since the first test by the US, which had no predecessor.  If the mean were constant, it would be 74 / 8 = 9.25 years between 'first tests', which seems consistent with the plot.   

This plot displays an estimated mean time to the next 'first test' starting around 7 years and increasing after 1960 to over 13 years, on average. 

It seems somewhat surprising that the line doesn't go between RU and GB and between FR and CN.  However, the arguments that should affect that, `a1`, `P1`, and `sd_level`, were set at levels that would support this. 

Apart from that, these estimates overall seem plausible.  

Let's check one more thing to evaluate our understanding of the MCMC algorithm used:  Is there a relationship between the root mean square of  [`diff`](https://www.rdocumentation.org/packages/base/versions/3.6.1/topics/diff) of each simulated trajectory of log(Poisson mean) and the corresponding element of `theta`?  

```{r rms}



```

# Cumulative number of nuclear-weapon states

What about the cumulative number of nuclear-weapon states?  This should be [`cumsum(exp(alpha))`](https://www.rdocumentation.org/packages/base/versions/3.6.1/topics/cumsum), adding 1 for the US.  

However, we cannot get confidence limits on the `cumsum` by summing the individual confidence limits, for the same reason that the standard deviation of a sum of random variables is generally not the sum of their standard deviations.  We need to compute the mean and quantiles of the  (`n_iter - n_burnin`) simulations retained after burn-in for each simulated year:  

 {r newNucStates}
lvlAll <- expand_sample(firstTstsSim, "alpha")
str(lvlAll)
lvlEnew <- ts(exp(t(lvlAll$level)), firstYear+1)
str(lvlEnew)
plot(lvlEnew[, 1:10])
```

This shows something of how the `bssm` MCMC algorithm works:  A visual inspection of one simulation suggested that the first 10 of the 2500 simulated series include only 4 unique simulations replicated 2, 2, 1, and at least 5 times, which matches `firstTstsSim$counts[1:4]`:

 {r firstTstsCounts}
firstTstsSim$counts[1:5]
```

`str(firstTstsSim)` above showed that "Length of the final jump chain = 648" for one simulation.  

The `cumsum` of each simulation in `lvlEnew` represents the simulated expected number of new nuclear-weapon states since the US became the first in 1945.  Add one to get the expected total number of nuclear-weapon states over time in each of the 2500 simulations:  

 {r nucStts}
str(lvlEnuc2 <- apply(lvlEnew, 2, cumsum))
plot(lvlEnuc2[, 1])
```

Confirmed that this gives us a cumulative sum.  

 {r nucStates}
lvlEnucStates <- ts(1+lvlEnuc2, firstYear+1) 
str(lvlEnucStates)
lvlMean <- ts(apply(lvlEnucStates, 1, mean), 
                    firstYear+1) 
str(lvlMean)
lvlQuant <- ts(t(apply(lvlEnucStates, 1, 
      quantile, probs=c(0.025, .5, .975))),
                    firstYear+1) 
str(lvlQuant)

ts.plot(lvlMean, lvlQuant, 
    col=c(2, 3, 4, 3), 
    lty=c(1, 2, 2, 2), log='y', 
    gpars=list(las=1), xlab='', 
    ylab='Number of nuclear-weapon states', 
    main=paste('Number of nuclear-weapon',
               'states by year') )

legend('bottomright', 
  legend=c('mean', 
    'median', 
    '95% CI (MCMC)'), 
  col=c(2, 4, 3), 
  lty=c(1, 2, 2), bty='n')

fT_date <- c(nuclearWeaponStates$firstTestYr, 
             currentYear+1)
nNucStates <- nrow(nuclearWeaponStates)
lines(fT_date, 
    c(1:nNucStates, nNucStates), type='s')
```

The upper and lower limits display the range of plausibilty for trajectories of the meanes of Poisson processes consistent with the available data:  Lines below the lower limit would not likely have produced as many nuclear-weapon states during this period as we have today.  Lines above the upper limit likely would have produced more than the number that exists today.  

The median goes right through the available data.  The mean looks a little high.  Overall this looks like a great fit, apart from the fact that all the increments decrease log(Poisson mean).  For that we should consider adding a slope term to the model, which we consider next.  

# Growing understanding of the risks 

The model considered so far assumes a Gaussian random walk in one dimension.  

The last plot suggest we consider adding another term, linear in log(time since the very first test of a nuclear weapon by the US).  

Before trying a more sophisticated model, let's plot the estimated trend above by itself to see if that supports adding log(time since the very first test of a nuclear weapon by the US) to the model.  

 {r plotTrend0}
op <- par(mar=c(5,4,4,4))
ts.plot(exp(lvl), gpars=list(las=1),
      xlab='', ylab='Poisson mean', 
      main=paste("mean number of 'first tests'",
          "each year"), log='y')

# add a scale for log(Poisson mean)
lvlLim1 <- range(lvl)
lvlLogTick1 <- pretty(lvlLim1)
axis(4, exp(lvlLogTick1), lvlLogTick1, 
     las=1)
mtext('log(Poisson mean)', 4, 3)
par(op)
```

The plot of log(Poisson rate) vs. time encourages us to consider adding time as a linear term.  A state-space model that is essentially equivalent has a slope term.

The same [`ng_bsm` function](https://www.rdocumentation.org/packages/bssm/versions/0.1.7/topics/ng_bsm) used above includes an `sd_slope` argument, which is "A fixed value or a prior for the standard error of the noise in slope equation."  Let's specify that as a normal with mean 0 and standard deviation being the root mean square increments in the estimate of level in the level-only model above:  

 {r firstTstsPois1}
firstTstsLin <- ng_bsm(FirstTests$nFirstTests, 
    sd_level=halfnormal(sd_lvl, 10*sqrt(P1)), 
    sd_slope=normal(0, 0, sd_lvl), 
    a1=c(a1, -sd_lvl), P1=P1*diag(c(1, 100)), 
    distribution='poisson')
str(firstTstsLin)
```

Let's proceed to estimate parameters as before:  

 {r run_mcmc2}
set.seed(2)
firstTstsSim2 <- run_mcmc(firstTstsLin, 
          nsim_states=2, n_iter = 5000)
firstTstsSim2
```

This says, "Acceptance rate after the burn-in period:  0".  Let's try to tighten the prior:  

 {r firstTstsPois2}
firstTstsLin2 <- ng_bsm(FirstTests$nFirstTests, 
    sd_level=halfnormal(sd_lvl, 0.1*sqrt(P1)), 
    sd_slope=normal(0, 0, 0.1*sd_lvl), 
    a1=c(a1, -sd_lvl), P1=0.01*P1*diag(c(1, 1)), 
    distribution='poisson')
#str(firstTstsLin2)
```

Let's proceed to estimate parameters as before:  

 {r run-mcmc2a}
set.seed(3)
firstTstsSim2a <- run_mcmc(firstTstsLin, 
          nsim_states=2, n_iter = 5000)
firstTstsSim2a
```

The acceptance rate is still 0.  Maybe a model this complicated cannot be estimated with the available data.  

We therefore return to the first model and see what predictions we can get from that.  

# Predict 

Let's use the 74 years of history available in late 2019 to predict another 74 years into the future.  For this, we use [predict.mcmc_output](https://www.rdocumentation.org/packages/bssm/versions/0.1.7/topics/predict.mcmc_output).  We start by producing a `future_model`, as in the example in the help page and the `bssm` vignette:  

 {r futureModel}
firstTstsFutureMdl <- firstTstsMdl
firstTstsFutureMdl$y <- ts(rep(NA, 74), 
                    start=currentYear+1)
```

 {r predict-mcmc}
set.seed(4)
firstTstsPred_r <- try(predict(firstTstsSim,
      firstTstsFutureMdl, 
      return_MCSE = TRUE))
str(firstTstsPred_r)
with(firstTstsPred_r, ts.plot(
  mean, intervals, gpars=list(las=1), 
  main='predict(...type="response")', 
  col=1:4, lty=1:4, lwd=c(1,2,2,2)) )
legend('topleft', 
  legend=c('mean', "95%", "50%", "5%"), 
  col=c(1, 4:2), lty=c(1, 4:2),
  lwd=c(1,2,2,2), bty='n')

firstTstsPred_m <- try(predict(firstTstsSim,
      type='mean', firstTstsFutureMdl, 
      return_MCSE = TRUE))
str(firstTstsPred_m)
with(firstTstsPred_m, ts.plot(
  mean, intervals, gpars=list(las=1), 
  main='predict(...type="mean")', 
  col=1:4, lty=1:4, lwd=c(1, 2,2,2)) )
legend('topleft', 
  legend=c('mean', "95%", "50%", "5%"), 
  col=c(1, 4:2), lty=c(1, 4:2),
  lwd=c(1,2,2,2), bty='n')

firstTstsPred_s <- try(predict(firstTstsSim,
      type='state', firstTstsFutureMdl, 
      return_MCSE = TRUE))
str(firstTstsPred_s)
with(firstTstsPred_s, ts.plot(
  mean, intervals$level, 
  gpars=list(las=1), 
  main='predict(...type="state")', 
  col=1:4, lty=1:4, lwd=c(1,2,2,2)) )
legend('topleft', 
  legend=c('mean', "95%", "50%", "5%"), 
  col=c(1, 4:2), lty=c(1, 4:2),
  lwd=c(1,2,2,2), bty='n')
```

It's not obvious what type = "response" or "mean" are in this context, but type = "state" seems potentially useful.  

However, we really want the cumsum(annual Poisson counts).  To get that, it would be easiest if we had simulated trajectories of log(Poisson means of annual counts).  Then we could compute cumsum(exp(log(Poisson means))) and compute mean and quantiles from those numbers.    

From that, we could estimate the probability of 0, 1, 2, or more currently non-nuclear states (or non-state rebel groups) becoming nuclear as a function of the time into the future. 

We will construct these manually in two different ways:   

* Assuming the annual changes in log(Poisson mean number of new nuclear-weapon states each year) have mean 0 and standard deviation given by the estimate of `theta` in each accepted MCMC simulation. 

* Using the estimated first differences from the level-only model.  






The first gives pessimistic estimates, basically assuming that the trend toward decreasing hazard showing in the plots in the introduction above could be reversed by a new arms race exemplified by the current nuclear expansion programs in India, Pakistan, the US,^[@Shultz:2019; @Helfand:2019] and Russia as well as the declared desire of the President of Turkey for nuclear weapons^[@OConnor:2019] and the increased threat that such weapons could fall into the hands of terrorists who believe that Armageddon may be a good thing, for whom the possession of nuclear weapons is more of a motivator than a deterrent.^[@Bacevich:2008, pp. 178-179; @Cohen:2009;  see also @Borger:2010]

The second essentially assumes a continuation of the trend visible in the plots above showing gradual reductions in the rate of nuclear proliferation.  

We will examine these two alternative simulations in the order stated, recognizing that the reality could be some in between with a nonzero probability of the elimination of the threat through the entering into force of the International Treaty on the Abolition of Nuclear Weapons, followed by the success of other more aggressive efforts to strengthen international law to the point that any nation that invades another can expect massive nonviolent retaliation in trade restrictions and confiscation of foreign held property of people in the nation of the apparent aggressor(s).  

# Predictions assuming the level-only model

Our primary model estimated in `firstTstsSim` assumes that log(Poisson mean) follows a random walk with independent annual increments of mean 0 and standard deviation `theta`.  Our approach here will iterate over all 2500 accepted simulations after burn-in, matching the log(Poisson mean[2020]) from `firstTstsSims$level[i, 75]` with the estimate of the corresponding standard deviation in theta[i, 1]:

 {r manualPred}
manPred <- ts(matrix(NA, 75, 2500), 
    start=currentYear+1)

manPred[1, ] <- (firstTstsSims$level[,
      75] + rnorm(75, 0, theta[, 1]) )

for(iyr in 2:75){
  manPred[iyr, ] <- (manPred[iyr-1, ] + 
        rnorm(2500, 0, theta[, 1]) )
}
```

Next we want to exponentiate these numbers and cumsum each row to get the expected number of new nuclear-weapon states for each simulated future year:  

 {r predCumsum}
str(predEnuc2 <- ts(apply(exp(manPred), 2,
          cumsum), currentYear+1) )
ts.plot(predEnuc2[, 1:10], lty=1:10, col=1:10)
```

Now let's add the current nuber of nuclear weapon states, 9 as this is being written on 2019-11-02, to predict the total number of nuclear-weapon states for the next 74 years:    

 {r predStates}
predEnucStates <- (9+lvlEnuc2) 
predEnucStates <- ts(9+lvlEnuc2,
                  currentYear+1) 
str(predEnucStates)
predMean <- ts(apply(predEnucStates, 
        1, mean), currentYear+1) 
str(predMean)
predQ <- apply(predEnucStates, 1, 
    quantile, probs=c(0.05, .5, .95))
predQuant <- ts(t(predQ),
                currentYear+1) 
str(predQuant)

yLab <- 'number of nuclear-weapon states'
plot(c(firstYear, currentYear+75), 
     c(1, max(predQuant)), type='n', 
     xlab='', ylab=yLab, las=1)
lines(fT_date, 
    c(1:nNucStates, nNucStates), type='s')
lines(predMean, lty=2, col=2)

predYrs <- time(predQuant)
matlines(predYrs, predQuant, lty=2, 
      col=c(3, 4, 3) )
      
legend('topleft', 
  legend=c('mean', 
    'median', 
    '90% CI (MCMC)'), 
  col=c(2, 4, 3), 
  lty=c(1, 2, 2), bty='n')
```

The model assumes that the `log(level[i])`, where `i` = a year after 2020, is based on the following recursion:  

<center>
`log(Poisson mean[i+1]) = log(Poisson[i]) + (independent random increment)`.
</center>
<cr>

The mean of the independent increments is 0 with a standrd deviation given by the posterior distribution of the variable `theta` described above. 

Let's start by selecting nYrs from the available MCMC simulations after burn-in:

 {r sample}
firstTstsFutureMdl$smpl <- sample(
  with(firstTstsSim, n_iter - n_burnin),
  nYrs)
plot(firstTstsFutureMdl$smpl)
```

We select MCMC samples this way, in case there's a relationship between the MCMC simulations in `theta` and `alpha` stored in `firstTstsSim`, above.  

Now let's select the log(Poisson mean) for each predicted year from the distribution for `(currentYear+1)`:  

 {r simLevel}
firstTstsFutureMdl$simLevel <- ts(
  lvlAll$level[firstTstsFutureMdl$smpl, 
        nYrs+1], currentYear+1)
```

Let's similary select the standard deviation of these estimated levels from `theta`: 

 {r simSD}
firstTstsFutureMdl$simSD <- ts(
  theta[firstTstsFutureMdl$smpl, 1], 
  currentYear+1)
```

Now let's predict the future mean number of nuclear-weapon states by adding `cumsum(exp(firstTstsFutureMdl$simLevel))` to the current number of nuclear-weapon states:  

 {r predNucStates}
firstTstsFutureMdl$predNucStates <- 
  nrow(nuclearWeaponStates) + cumsum(exp(
    firstTstsFutureMdl$simLevel))
plot(firstTstsFutureMdl$predNucStates)
```


)


Similarly, the variance of the prediction e


at time $t$, where $t$ > 
independent normal increments to 





# Conclusions 

This article has modeled the production of nuclear-weapon states as a renewal process with non-identially distributed times between events.  People like [Robert McNamara](https://en.wikipedia.org/wiki/Robert_McNamara), [Daniel Ellsberg](https://en.wikipedia.org/wiki/Daniel_Ellsberg), [Henry Kissinger](https://en.wikipedia.org/wiki/Henry_Kissinger), [William Perry](https://en.wikipedia.org/wiki/William_Perry), [Sam Nunn](https://en.wikipedia.org/wiki/Sam_Nunn), [George Schultz](https://en.wikipedia.org/wiki/George_Shultz), and others with the [Nuclear Threat Initiative](https://en.wikipedia.org/wiki/Nuclear_Threat_Initiative) have said that as long as the world maintains large nuclear arsenals, it's only a matter of time before a nuclear war occurs.  The present work only makes those calls more urgent: As long as the nations of the world fail to provide effective judicial recourse to perceived threats, non-nuclear nations and terrorist groups will feel a need to obtain nuclear weapons, which become more available with the passage of time.  This article has estimated tolerance intervals for the time to the next new nuclear nation using a renewal process with log hazard for the increments being linear in the time since the first successful [Trinity test](https://en.wikipedia.org/wiki/Trinity_(nuclear_test)), 1945-07-16. 

# Appendix.  Plotting to a file 

Plotting the time between first tests to a file was surprisingly difficult, because font sizes in the files were smaller than the standard display, and getting larger fonts was surprisingly difficult.  Consider the following:

````{r png}
if(FALSE){
  png('nuclearProliferation.png', 1440, 1200)
  par(mar=c(15, 12, 4, 2)+.1)
  plot(yearsSinceLastFirstTest~firstTest, 
     nuclearWeaponStates, type='h', 
     xlab='', ylab='', las=1, cex.axis=4, 
     bty='n', axes=FALSE, lwd=2, 
     ylim=ylim.)
  xyr <- seq(1950, 2000, 10)
  xt. <- paste0(xyr, '-01-01')
  xticks <- as.Date(xt.)
  axis(1, xticks, labels=FALSE, lwd=2)
  axis(1, xticks, xyr, cex.axis=4, lwd=0, line=2)
#axis(1, seq(1950, 2000, by=10), cex.axis=4, lwd=0, line=1)
  axis(2, cex.axis=4, las=1, lwd=2)
  title('Time between new nuclear nations', 
      cex.main=4)
addCountries(line=c(12, 2), cex.=4)
#mtext(paste0(
#'Note: The US is not on this plot,', 
#'\nbecause it had no predecessors.'), 
#1, 12, cex=4)
#mtext('years from the\nprevious "first test"',
#      2, 5, cex=4)
#  with(nuclearWeaponStates, 
#    text(firstTest, yearsSinceLastFirstTest,
#       ctry, xpd=TRUE, cex=4))
  dev.off()
}
```

Plot to an svg file, killing the labels for Wikimedia Commons:  

```{r svg}
if(FALSE){
  svg('nuclearProliferation.svg', 14, 11)
  Label. <- FALSE
  par(mar=c(9, 8, 4, 2)+.1)
  cex. <- 4
  plot(yearsSinceLastFirstTest~firstTest, 
     nuclearWeaponStates, type='h', 
     xlab='', ylab='', axes=FALSE, 
     bty='n', ylim=ylim.)
#  axis(1, cex.axis=cex., line=1)
  axis(1, labels=FALSE)
  axis.Date(1,
    nuclearWeaponStates$firstTest, 
    tick=FALSE, cex.axis=cex., line=2)
  axis(2, cex.axis=cex., las=1)
  if(Label.)title(
    'Time between new nuclear nations',
                  cex.main=2)
  if(Label.)addCountries(line=c(6, 4), cex=cex., 
        mtext.=Label.)  
#  noUS <- paste0(
#    'Note: The US is not on this plot,', 
#    '\nbecause it had no predecessors.')
#  if(Label.)mtext(noUS, 1, 6, cex=cex.)
#  ylab. <- paste(
#    'years from the\nprevious "first test"')
#  if(Label.)mtext(ylab., 2, 4, cex=cex.)
#  with(nuclearWeaponStates, 
#    text(firstTest, yearsSinceLastFirstTest,
#       ctry, xpd=TRUE, cex=cex.))
  dev.off()
}
```

Plot to png, killing the labeling for Wikimedia Commons

````{r png2}
#ymax <- max(nuclearWeaponStates$yearsSinceLastFirstTest, 
#            na.rm=TRUE)
#ylim. <- c(0, ymax)

png. <- FALSE
cex.ax=1 
lbl <- TRUE
if(png.){ 
    png('nuclearProliferation.png', 1440, 1200)
  if(lbl){
#    par(mar=c(15, 15, 7, 2)+.1)
    par(mar=c(15, 15, 2, 2)+.1)
  } else par(mar=c(5, 5, 2, 2)+.1)
    cex.ax=4
}
plotNucStates(type='h', ylim.=ylim0, 
    line.=3:2, cex.=cex.ax, mtext.=lbl, log.='', 
    axes=FALSE)
    
#plot(yearsSinceLastFirstTest~firstTest, 
#     nuclearWeaponStates, type='h', 
#     xlab='', ylab='', las=1, cex.axis=cex.ax, 
#     bty='n', axes=FALSE, lwd=2, ylim=ylim.)
#if(lbl){
#  title('Figure 1. Time between\nnew nuclear nations', 
#    cex.main=cex.ax)
#addCountries(line=c(11, 6), cex=cex.ax)
#  xlab. <- paste(c('Note: The US is not on this plot,',
#                   'because it had no predecessors.'), 
#                 collapse='\n')
#  mtext(xlab., 1, 11, cex=cex.ax)
#  mtext('years from the\nprevious "first test"',
#        2, 6, cex=cex.ax)
#}
xyr <- seq(1950, 2000, 10)
xt. <- paste0(xyr, '-01-01')
xticks <- as.Date(xt.)
axis(1, xticks, labels=FALSE, lwd=2)
axis(1, xticks, xyr, cex.axis=cex.ax, lwd=0, line=0)
#axis(1, seq(1950, 2000, by=10), cex.axis=4, lwd=0, line=1)
axis(2, cex.axis=cex.ax, las=1, lwd=2)
#  title('Time between new nuclear nations', cex.main=4)
#xlab. <- paste0('Note: The US is not on this plot,', 
#    '\nbecause it had no predecessors.')
#  mtext(xlab., 1, 12, cex=4)
#ylab. <- paste0('Note: The US is not on this plot,', 
#    '\nbecause it had no predecessors.')
#  mtext(ylab., 1, 12, cex=4)
#  with(nuclearWeaponStates, 
#    text(firstTest, yearsSinceLastFirstTest,
#       ctry, xpd=TRUE, cex=cex.ax))
if(png.) dev.off()

```


# Predictions using the actual increments in the MCMC simulations




# References

[^India]: [India had military conflicts with China in 1962 and 1967](https://en.wikipedia.org/wiki/China%E2%80%93India_relations) before India's first nuclear weapon's test 1974-05-18.  India and China have continued to have conflicts, including, e.g., [the Doklam standoff in 2017](https://en.wikipedia.org/wiki/2017_China%E2%80%93India_border_standoff).

[^Pak]: [India-Pakistan relations](https://en.wikipedia.org/wiki/India%E2%80%93Pakistan_relations) have been marked by frequent conflict since the two nations were born with the dissolution of the British Raj in 1947.  This history might help people understand the need that Pakistani leaders may have felt and still feel for nuclear parity with India. 

[^Israel]: [Israel faced many threats from its Arab neighbors before it became an independent nation in 1949](https://en.wikipedia.org/wiki/Arab%E2%80%93Israeli_conflict). These have continued, including the [Gaza border protests](https://en.wikipedia.org/wiki/2018_Gaza_border_protests) that have continued at least to mid 2019.  One might therefore reasonably understand why Israel might feel a need for nuclear weapons and why others might believe that the 1979-09-22 [Vela incident](https://en.wikipedia.org/wiki/Vela_Incident) was an Israeli nuclear test. 

[^quickNukes]: In addition to the 32 currently non-nuclear-weapon states with "sufficient fissile material to make nuclear weapons if they wished", per @Toon:2007, the inspector general of the US Department of Energy concluded in 2009 (in its most recent public accounting) that enough highly enriched uranium was missing from US inventories to make at least five nuclear bombs comparable to those that destroyed substantial portions of Hiroshima and Nagasaki in 1945.  Substantially more weapons-grade materials may be missing in other countries, especially Russia (@Malone:2018).   

[^ranWalk]: The [`bssm` package](https://www.rdocumentation.org/packages/bssm/versions/0.1.7) provides a reasonable framework for modeling this.  Its [`ng_bsm` function](https://www.rdocumentation.org/packages/bssm/versions/0.1.7/topics/ng_bsm) supports modeling a normal random walk in log(Poisson mean) of the number of "first tests" each year with the log(Poisson mean). This uses the fact that [the probability distribution of the time between events in a Poisson point process is exponential](https://en.wikipedia.org/wiki/Exponential_distribution).   

[^WikivTime]: For precursors to the current study that involve censored estimation of time to a nuclear war, see @Wikiv:extinct and @Wikiv:Armageddon.  